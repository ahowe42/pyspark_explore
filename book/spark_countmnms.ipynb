{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "promotional-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *#avg, count, expr\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "opposite-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext()\n",
    "ss = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "spare-ordering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "100006 records\n",
      "[Row(State='TX', Color='Red', Count=20), Row(State='NV', Color='Blue', Count=66), Row(State='CO', Color='Blue', Count=79), Row(State='OR', Color='Blue', Count=71), Row(State='WA', Color='Yellow', Count=93)]\n"
     ]
    }
   ],
   "source": [
    "# ingest the file\n",
    "fil = './LearningSparkV2-master/chapter2/py/src/data'\n",
    "data = ss.read.load(fil, format='com.databricks.spark.csv', header='True', inferSchema='true')\n",
    "print(type(data))\n",
    "print('%d records'%data.count())\n",
    "print('%s'%data.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "military-bridal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State|Color |Total|\n",
      "+-----+------+-----+\n",
      "|CA   |Yellow|1807 |\n",
      "|WA   |Green |1779 |\n",
      "|OR   |Orange|1743 |\n",
      "|TX   |Green |1737 |\n",
      "|TX   |Red   |1726 |\n",
      "|CA   |Green |1723 |\n",
      "|CO   |Yellow|1721 |\n",
      "|CA   |Brown |1718 |\n",
      "|CO   |Green |1713 |\n",
      "|NV   |Orange|1712 |\n",
      "|TX   |Yellow|1703 |\n",
      "|NV   |Green |1698 |\n",
      "|AZ   |Brown |1698 |\n",
      "|CO   |Blue  |1697 |\n",
      "|WY   |Green |1695 |\n",
      "|NM   |Red   |1690 |\n",
      "|AZ   |Orange|1689 |\n",
      "|NM   |Yellow|1688 |\n",
      "|NM   |Brown |1687 |\n",
      "|UT   |Orange|1684 |\n",
      "|NM   |Green |1682 |\n",
      "|UT   |Red   |1680 |\n",
      "|AZ   |Green |1676 |\n",
      "|NV   |Yellow|1675 |\n",
      "|NV   |Blue  |1675 |\n",
      "|WA   |Red   |1671 |\n",
      "|WY   |Red   |1670 |\n",
      "|WA   |Brown |1669 |\n",
      "|NM   |Orange|1665 |\n",
      "|WY   |Blue  |1664 |\n",
      "|WA   |Yellow|1664 |\n",
      "|WA   |Orange|1658 |\n",
      "|NV   |Brown |1657 |\n",
      "|CA   |Orange|1657 |\n",
      "|CA   |Red   |1656 |\n",
      "|CO   |Brown |1656 |\n",
      "|UT   |Blue  |1655 |\n",
      "|AZ   |Yellow|1654 |\n",
      "|TX   |Orange|1652 |\n",
      "|AZ   |Red   |1648 |\n",
      "|OR   |Blue  |1647 |\n",
      "|OR   |Red   |1645 |\n",
      "|UT   |Yellow|1645 |\n",
      "|CO   |Orange|1642 |\n",
      "|TX   |Brown |1641 |\n",
      "|NM   |Blue  |1638 |\n",
      "|AZ   |Blue  |1636 |\n",
      "|OR   |Green |1634 |\n",
      "|UT   |Brown |1631 |\n",
      "|WY   |Yellow|1626 |\n",
      "|WA   |Blue  |1625 |\n",
      "|CO   |Red   |1624 |\n",
      "|OR   |Brown |1621 |\n",
      "|TX   |Blue  |1614 |\n",
      "|OR   |Yellow|1614 |\n",
      "|NV   |Red   |1610 |\n",
      "|CA   |Blue  |1603 |\n",
      "|WY   |Orange|1595 |\n",
      "|UT   |Green |1591 |\n",
      "|WY   |Brown |1532 |\n",
      "+-----+------+-----+\n",
      "\n",
      "Total Rows = 60\n"
     ]
    }
   ],
   "source": [
    "# agg by state & color\n",
    "count_mnm_df = data.select(\"State\", \"Color\", \"Count\").groupBy(\"State\", \"Color\").agg(count('Count').alias('Total')).orderBy('Total', ascending=False)\n",
    "count_mnm_df.show(n=60, truncate=False)\n",
    "print(\"Total Rows = %d\" % (count_mnm_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "straight-underwear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State|Color |Total|\n",
      "+-----+------+-----+\n",
      "|CA   |Yellow|1807 |\n",
      "|CA   |Green |1723 |\n",
      "|CA   |Brown |1718 |\n",
      "|CA   |Orange|1657 |\n",
      "|CA   |Red   |1656 |\n",
      "|CA   |Blue  |1603 |\n",
      "+-----+------+-----+\n",
      "\n",
      "Total Rows = 6\n"
     ]
    }
   ],
   "source": [
    "ca_count_mnm_df = data.select(\"State\", \"Color\", \"Count\").where(data.State == \"CA\").groupBy(\"State\", \"Color\").agg(count('Count').alias('Total')).orderBy(\"Total\", ascending=False)\n",
    "ca_count_mnm_df.show(n=60, truncate=False)\n",
    "print(\"Total Rows = %d\" % (ca_count_mnm_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "wrapped-addition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  name|avg(age)|\n",
      "+------+--------+\n",
      "|Brooke|    22.5|\n",
      "| Jules|    30.0|\n",
      "|    TD|    35.0|\n",
      "| Denny|    31.0|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df = ss.createDataFrame([(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30), (\"TD\", 35), (\"Brooke\", 25)], [\"name\", \"age\"])\n",
    "avg_df = data_df.groupBy(\"name\").agg(avg(\"age\"))\n",
    "avg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "spectacular-bidding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+----------+-----+--------------------+\n",
      "| Id|    First|   Last|              URL| Published| Hits|           Campaigns|\n",
      "+---+---------+-------+-----------------+----------+-----+--------------------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1|2016-01-04| 4535| [twitter, LinkedIn]|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2|2018-05-05| 8908| [twitter, LinkedIn]|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3|2019-06-07| 7659|[web, twitter, FB...|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|2018-05-12|10568|       [twitter, FB]|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|2014-05-14|40578|[web, twitter, FB...|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6|2015-03-02|25568| [twitter, LinkedIn]|\n",
      "+---+---------+-------+-----------------+----------+-----+--------------------+\n",
      "\n",
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- First: string (nullable = true)\n",
      " |-- Last: string (nullable = true)\n",
      " |-- URL: string (nullable = true)\n",
      " |-- Published: date (nullable = true)\n",
      " |-- Hits: integer (nullable = true)\n",
      " |-- Campaigns: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define a schema (2 ways)\n",
    "schema = StructType([StructField('Id', IntegerType()), StructField('First', StringType()), StructField('Last', StringType()),\n",
    "                     StructField('URL', StringType()), StructField('Published', DateType()), StructField('Hits', IntegerType()),\n",
    "                     StructField('Campaigns', ArrayType(StringType()))])\n",
    "# \"`Id` INT, `First` STRING, `Last` STRING, `Url` STRING, `Published` STRING, `Hits` INT, `Campaigns` ARRAY<STRING>\"\n",
    "\n",
    "# create data\n",
    "data = [[1, \"Jules\", \"Damji\", \"https://tinyurl.1\", dt.date(2016, 1, 4), 4535, [\"twitter\",\"LinkedIn\"]],\n",
    "        [2, \"Brooke\",\"Wenig\", \"https://tinyurl.2\", dt.date(2018, 5, 5), 8908, [\"twitter\", \"LinkedIn\"]],\n",
    "        [3, \"Denny\", \"Lee\", \"https://tinyurl.3\", dt.datetime(2019, 6, 7), 7659, [\"web\",\"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "        [4, \"Tathagata\", \"Das\", \"https://tinyurl.4\", dt.date(2018, 5, 12), 10568,[\"twitter\", \"FB\"]],\n",
    "        [5, \"Matei\",\"Zaharia\", \"https://tinyurl.5\", dt.date(2014, 5, 14), 40578, [\"web\",\"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "        [6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", dt.date(2015, 3, 2), 25568,[\"twitter\", \"LinkedIn\"]]]\n",
    "\n",
    "# put together as a spark dataframe\n",
    "blogs_df = ss.createDataFrame(data, schema)\n",
    "blogs_df.show()\n",
    "blogs_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "stuck-personal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+----+---------+----+---------+\n",
      "|  Id|First|Last| URL|Published|Hits|Campaigns|\n",
      "+----+-----+----+----+---------+----+---------+\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "|null| null|null|null|     null|null|     null|\n",
      "+----+-----+----+----+---------+----+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- First: string (nullable = true)\n",
      " |-- Last: string (nullable = true)\n",
      " |-- URL: string (nullable = true)\n",
      " |-- Published: string (nullable = true)\n",
      " |-- Hits: integer (nullable = true)\n",
      " |-- Campaigns: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use same schema reading data from json - not working?\n",
    "schema = StructType([StructField('Id', IntegerType()), StructField('First', StringType()), StructField('Last', StringType()),\n",
    "                     StructField('URL', StringType()), StructField('Published', StringType()), StructField('Hits', IntegerType()),\n",
    "                     StructField('Campaigns', ArrayType(StringType()))])\n",
    "\n",
    "fil = './LearningSparkV2-master/chapter3/data'\n",
    "fromjson_df = ss.read.schema(schema).json(fil)\n",
    "fromjson_df.show()\n",
    "fromjson_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "entertaining-throw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Id', 'First', 'Last', 'URL', 'Published', 'Hits', 'Campaigns']\n",
      "DataFrame[Id: int]\n",
      "DataFrame[Id: int]\n"
     ]
    }
   ],
   "source": [
    "print(blogs_df.columns)\n",
    "print(blogs_df.select(col('Id')))\n",
    "print(blogs_df.select('Id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "satisfied-privacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|(Hits * 2)|\n",
      "+----------+\n",
      "|      9070|\n",
      "|     17816|\n",
      "|     15318|\n",
      "|     21136|\n",
      "|     81156|\n",
      "|     51136|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blogs_df.select(expr(\"Hits*2\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "brazilian-outdoors",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+----------+-----+--------------------+----------+\n",
      "| Id|    First|   Last|              URL| Published| Hits|           Campaigns|Influencer|\n",
      "+---+---------+-------+-----------------+----------+-----+--------------------+----------+\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|2014-05-14|40578|[web, twitter, FB...|      true|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|2018-05-12|10568|       [twitter, FB]|      true|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6|2015-03-02|25568| [twitter, LinkedIn]|      true|\n",
      "|  1|    Jules|  Damji|https://tinyurl.1|2016-01-04| 4535| [twitter, LinkedIn]|     false|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2|2018-05-05| 8908| [twitter, LinkedIn]|     false|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3|2019-06-07| 7659|[web, twitter, FB...|     false|\n",
      "+---+---------+-------+-----------------+----------+-----+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blogs_df.withColumn('Influencer', expr('Hits > 10000')).orderBy('Influencer', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "written-plain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|    Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         null|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13|     2.95|\n",
      "|  20110022|   M17|       2003241|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 03:01:...|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         null|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|      4.7|\n",
      "|  20110023|   M41|       2003242|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 02:39:...|MARKET ST/MCALLIS...|  SF|  94102|      B03|         01|1455|               3|       3|            3|   true|         null|        1|   MEDIC|                         2|                     3|                 6|          Tenderloin|(37.7811772186856...|020110023-M41|2.4333334|\n",
      "|  20110032|   E11|       2003250|    Vehicle Fire|01/11/2002|01/10/2002|               Other|01/11/2002 04:16:...|APPLETON AV/MISSI...|  SF|  94110|      B06|         32|5626|               3|       3|            3|  false|         null|        1|  ENGINE|                         1|                     6|                 9|      Bernal Heights|(37.7388432849018...|020110032-E11|      1.5|\n",
      "|  20110043|   B04|       2003259|          Alarms|01/11/2002|01/10/2002|               Other|01/11/2002 06:01:...|1400 Block of SUT...|  SF|  94109|      B04|         03|3223|               3|       3|            3|  false|         null|        1|   CHIEF|                         2|                     4|                 2|    Western Addition|(37.7872890372638...|020110043-B04|3.4833333|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-professional",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-darkness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
