{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6884cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from itertools import chain\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *#avg, count, expr\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler, OneHotEncoder, MinMaxScaler, StringIndexer\n",
    "from pyspark.ml.fpm import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c365c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "sc = pyspark.SparkContext()\n",
    "spark = SparkSession(sc)\n",
    "spark.sparkContext.appName = 'fpmining'\n",
    "# show the number of cores\n",
    "print('%d cores'%spark._jsc.sc().getExecutorMemoryStatus().keySet().size())\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b238b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' get the data '''\n",
    "# load the data\n",
    "fil = '../data/data-final.csv'\n",
    "schem = StructType([StructField('EXT1', IntegerType()), StructField('EXT2', IntegerType()), StructField('EXT3', IntegerType()),\n",
    "StructField('EXT4', IntegerType()), StructField('EXT5', IntegerType()), StructField('EXT6', IntegerType()),\n",
    "StructField('EXT7', IntegerType()), StructField('EXT8', IntegerType()), StructField('EXT9', IntegerType()),\n",
    "StructField('EXT10', IntegerType()), StructField('EST1', IntegerType()), StructField('EST2', IntegerType()),\n",
    "StructField('EST3', IntegerType()), StructField('EST4', IntegerType()), StructField('EST5', IntegerType()),\n",
    "StructField('EST6', IntegerType()), StructField('EST7', IntegerType()), StructField('EST8', IntegerType()),\n",
    "StructField('EST9', IntegerType()), StructField('EST10', IntegerType()), StructField('AGR1', IntegerType()),\n",
    "StructField('AGR2', IntegerType()), StructField('AGR3', IntegerType()), StructField('AGR4', IntegerType()),\n",
    "StructField('AGR5', IntegerType()), StructField('AGR6', IntegerType()), StructField('AGR7', IntegerType()),\n",
    "StructField('AGR8', IntegerType()), StructField('AGR9', IntegerType()), StructField('AGR10', IntegerType()),\n",
    "StructField('CSN1', IntegerType()), StructField('CSN2', IntegerType()), StructField('CSN3', IntegerType()),\n",
    "StructField('CSN4', IntegerType()), StructField('CSN5', IntegerType()), StructField('CSN6', IntegerType()),\n",
    "StructField('CSN7', IntegerType()), StructField('CSN8', IntegerType()), StructField('CSN9', IntegerType()),\n",
    "StructField('CSN10', IntegerType()), StructField('OPN1', IntegerType()), StructField('OPN2', IntegerType()),\n",
    "StructField('OPN3', IntegerType()), StructField('OPN4', IntegerType()), StructField('OPN5', IntegerType()),\n",
    "StructField('OPN6', IntegerType()), StructField('OPN7', IntegerType()), StructField('OPN8', IntegerType()),\n",
    "StructField('OPN9', IntegerType()), StructField('OPN10', IntegerType()), StructField('EXT1_E', FloatType()),\n",
    "StructField('EXT2_E', FloatType()), StructField('EXT3_E', FloatType()), StructField('EXT4_E', FloatType()),\n",
    "StructField('EXT5_E', FloatType()), StructField('EXT6_E', FloatType()), StructField('EXT7_E', FloatType()),\n",
    "StructField('EXT8_E', FloatType()), StructField('EXT9_E', FloatType()), StructField('EXT10_E', FloatType()),\n",
    "StructField('EST1_E', FloatType()), StructField('EST2_E', FloatType()), StructField('EST3_E', FloatType()),\n",
    "StructField('EST4_E', FloatType()), StructField('EST5_E', FloatType()), StructField('EST6_E', FloatType()),\n",
    "StructField('EST7_E', FloatType()), StructField('EST8_E', FloatType()), StructField('EST9_E', FloatType()),\n",
    "StructField('EST10_E', FloatType()), StructField('AGR1_E', FloatType()), StructField('AGR2_E', FloatType()),\n",
    "StructField('AGR3_E', FloatType()), StructField('AGR4_E', FloatType()), StructField('AGR5_E', FloatType()),\n",
    "StructField('AGR6_E', FloatType()), StructField('AGR7_E', FloatType()), StructField('AGR8_E', FloatType()),\n",
    "StructField('AGR9_E', FloatType()), StructField('AGR10_E', FloatType()), StructField('CSN1_E', FloatType()),\n",
    "StructField('CSN2_E', FloatType()), StructField('CSN3_E', FloatType()), StructField('CSN4_E', FloatType()),\n",
    "StructField('CSN5_E', FloatType()), StructField('CSN6_E', FloatType()), StructField('CSN7_E', FloatType()),\n",
    "StructField('CSN8_E', FloatType()), StructField('CSN9_E', FloatType()), StructField('CSN10_E', FloatType()),\n",
    "StructField('OPN1_E', FloatType()), StructField('OPN2_E', FloatType()), StructField('OPN3_E', FloatType()),\n",
    "StructField('OPN4_E', FloatType()), StructField('OPN5_E', FloatType()), StructField('OPN6_E', FloatType()),\n",
    "StructField('OPN7_E', FloatType()), StructField('OPN8_E', FloatType()), StructField('OPN9_E', FloatType()),\n",
    "StructField('OPN10_E', FloatType()), StructField('dateload', TimestampType()), StructField('screenw', IntegerType()),\n",
    "StructField('screenh', IntegerType()), StructField('introelapse', IntegerType()), StructField('testelapse', FloatType()),\n",
    "StructField('endelapse', FloatType()), StructField('IPC', IntegerType()), StructField('country', StringType()),\n",
    "StructField('lat_appx_lots_of_err', FloatType()), StructField('long_appx_lots_of_err', FloatType())])\n",
    "bigfive = spark.read.format('csv').options(header=True, delimiter='\\t', timeStampFormat='yyyy-MM-dd HH:mm:ss').schema(schem).load(fil)\n",
    "\n",
    "# add an ID - don't actually care if it's monotonic; also filter for IP count is 1\n",
    "bigfive = bigfive.where(col('IPC') == 1).select(monotonically_increasing_id().alias('id'), '*')\n",
    "\n",
    "# talk\n",
    "cnt = bigfive.count()\n",
    "print('%d records'%cnt)\n",
    "bigfive.show(truncate=False)\n",
    "#bigfive.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e099cfe-d4ff-487c-8969-626e2f2f9f9c",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d612d95-39b5-4783-bb14-3eb2e34fd7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' handle missing values '''\n",
    "# check for missing values\n",
    "nullCounts = {colm:bigfive.select(colm).where(col(colm).isNull()).count() for colm in bigfive.columns}\n",
    "nullCounts = {colm:(ncnt, ncnt/cnt) for (colm, ncnt) in nullCounts.items()}\n",
    "nullCountsDF = pd.DataFrame(nullCounts).T.reset_index(drop=False).sort_values(1, ascending=False)\n",
    "nullCountsDF.columns = ['Column', 'Freq.', 'Rel. Freq.']\n",
    "nullCountsDF = nullCountsDF.merge(pd.DataFrame([[colm.name, colm.dataType] for colm in bigfive.schema], columns=['Column', 'Type']),\n",
    "                                how='inner', on=['Column'])\n",
    "\n",
    "# talk\n",
    "display(nullCountsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d2e4c-0f79-4aa7-9961-cd296b252213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nulls - only small amounts of nulls, so dropping\n",
    "bigfive = bigfive.dropna(how='any')\n",
    "\n",
    "# talk some more\n",
    "print('%d records'%bigfive.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb4476-6a38-4f64-8292-0e1fcc47d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Data Prep & Modeling with FP Growth '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c40337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' prepare the features '''\n",
    "# average the answers by \"type\"\n",
    "qTypes = {'EXT':[[1,3,5,7,9], [2,4,6,8,10]],\n",
    "          'EST':[[1,3,5,6,7,8,9,10], [2,4]],\n",
    "          'AGR':[[1,3,4,7,9], [2,4,6,8,10]],\n",
    "          'CSN':[[1,3,5,7,9,10], [2,4,6,8]],\n",
    "          'OPN':[[1,3,5,7,8,9,10], [2,4,6]]}\n",
    "# iterate over question types - skipping elapsed times because can't get the features I want\n",
    "features = list(qTypes.keys())\n",
    "for q in qTypes.keys():\n",
    "    print('Processing %s questions...'%q)\n",
    "    allQs = ['%s%d_E'%(q, cnt) for cnt in range(1, 11)]\n",
    "    q0 = ['%s%d'%(q, cnt) for cnt in qTypes[q][0]]\n",
    "    q1 = ['%s%d'%(q, cnt) for cnt in qTypes[q][1]]\n",
    "    # average the 0s, 1s scores, and sum the elapsed times (will use the latter later)\n",
    "    expr0 = '(' + '+'.join(q0) + ')/%d'%len(q0)\n",
    "    q0Nam = '%s_0'%q\n",
    "    expr1 = '(' + '+'.join(q1) + ')/%d'%len(q1)\n",
    "    q1Nam = '%s_1'%q\n",
    "    exprC = '(case when %s > %s then \"%s\" when %s > %s then \"%s\" else %s end)'%(q0Nam, q1Nam, q0Nam, q1Nam, q1Nam, q1Nam, '\"%s_neut\"'%q)\n",
    "    exprE = '+'.join(allQs)\n",
    "    bigfive = bigfive.withColumn('%s_0'%q, expr(expr0)).withColumn('%s_1'%q, expr(expr1)).\\\n",
    "        withColumn(q, expr(exprC)).withColumn('%s_E'%q, expr(exprE))\n",
    "    ''' old code wherein I kept the avg score & elapsed times separate - I think that data was too granular to give a resukt'''\n",
    "    #expr0 = 'cast((' + '+'.join(q0) + ')/%d as string)'%len(q0)\n",
    "    #expr1 = 'cast((' + '+'.join(q1) + ')/%d as string)'%len(q1)\n",
    "    #exprE = 'cast((' + '+'.join(allQs) + ')/10 as string)'\n",
    "    #bigfive = bigfive.withColumn('%s_E'%q, expr(exprE)).withColumn('%s_0'%q, expr(expr0)).withColumn('%s_1'%q, expr(expr1))\n",
    "    # update the q columns to be unique\n",
    "    #bigfive = bigfive.withColumn('%s_0'%q, concat_ws('_', lit('%s0'%q), '%s_0'%q)).withColumn('%s_1'%q, concat_ws('_', lit('%s1'%q), '%s_1'%q)).withColumn('%s_E'%q, concat_ws('_', lit('%sE'%q), '%s_E'%q))\n",
    "\n",
    "\n",
    "# get the q types on which the most and least time was spent - doesn't work, and don't know how to get the index of the min / max from the array col\n",
    "#bigfive = bigfive.withColumn('elapses', array(['%s_E'%q for q in qTypes.keys()]))\n",
    "#bigfive = bigfive.withColumn('elapsemax', array_position('elapses', array_max('elapses')))\\\n",
    "#    .withColumn('elapsemax', array_position('elapses', array_min('elapses')))\n",
    "\n",
    "    \n",
    "# add the screen area as a feature\n",
    "bigfive = bigfive.withColumn('screen_area', col('screenw')*col('screenh'))\n",
    "features.append('screen_area')\n",
    "\n",
    "# add total elapse as a feature\n",
    "bigfive = bigfive.withColumn('totalelapse', col('introelapse')+col('endelapse')+col('testelapse'))\n",
    "\n",
    "# finally add the rest of the features - ignoring introelapse & endelapse as they can be identical\n",
    "features.extend(['totalelapse', 'testelapse', 'country'])\n",
    "\n",
    "# add the array of features\n",
    "bigfive = bigfive.withColumn('items', array(*features))\n",
    "\n",
    "# talk\n",
    "bigfive.select('id', 'country', 'dateload', 'items').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bf49cf-1a63-4978-87fc-1b07b093f160",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d650d61f-d8ff-43ee-bc70-f360d8d01c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split for cross-val\n",
    "trainPerc = 0.7\n",
    "randSeed = 42\n",
    "tran, test = bigfive.select('id', 'items').randomSplit([trainPerc, 1.0 - trainPerc], seed=randSeed)\n",
    "\n",
    "# talk\n",
    "print('Training Cases')\n",
    "tran.select('id').show()\n",
    "print('Testing Cases')\n",
    "test.select('id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb222983-b161-44d0-ab9a-fe5689a7a1a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' fit frequent pattern growth model'''\n",
    "# fit on training set\n",
    "supp = 0.4\n",
    "conf = 0.6\n",
    "fpg = FPGrowth(itemsCol='items', minSupport=supp, minConfidence=conf)\n",
    "fpgmod = fpg.fit(tran)\n",
    "\n",
    "# predict on testing set\n",
    "preds = fpgmod.transform(test)\n",
    "preds.show(n=20, truncate=False)\n",
    "\n",
    "# frequent item sets mined - ordered by most frequent\n",
    "answerpop = fpgmod.freqItemsets\n",
    "answerpop = answerpop.withColumn('rel freq', col('freq')/bigfive.count())\n",
    "answerpop.orderBy(col('freq').desc()).show(n=20, truncate=False)\n",
    "\n",
    "# association rules - ordered by most confidence\n",
    "assocrule = fpgmod.associationRules\n",
    "assocrule.orderBy(col('confidence').desc()).show(n=20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2141e-3053-4421-9460-4ffdf355c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Data Prep & Modeling with Prefix Span'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0110ef-a8d4-4f2d-acb4-bfbe74ec836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' data prep '''\n",
    "# prep the elapsed times by question type\n",
    "bigfive = bigfive.withColumn('elapseMn', round(expr('(' + '+'.join(['EXT_E', 'EST_E', 'AGR_E', 'CSN_E', 'OPN_E']) + ')/5'), 0)).\\\n",
    "    withColumn('extE', (col('EXT_E')-col('elapseMn'))>0).withColumn('estE', (col('EST_E')-col('elapseMn'))>0).\\\n",
    "    withColumn('agrE', (col('AGR_E')-col('elapseMn'))>0).withColumn('csnE', (col('CSN_E')-col('elapseMn'))>0).\\\n",
    "    withColumn('opnE', (col('OPN_E')-col('elapseMn'))>0)\n",
    "\n",
    "# get pairs of odd-even question answers - the prefix span model expects an array of arrays\n",
    "bfps = bigfive.select('id', 'country', 'dateload', array(array('EXT1', 'EXT2'), array('EXT3', 'EXT4'), array('EXT5', 'EXT6'),\n",
    "                                                         array('EXT5', 'EXT6'), array('EXT7', 'EXT8'), array('EXT9', 'EXT10'),\n",
    "                                                         array('EST1', 'EST2'), array('EST3', 'EST4'), array('EST5', 'EST6'),\n",
    "                                                         array('EST5', 'EST6'), array('EST7', 'EST8'), array('EST9', 'EST10'),\n",
    "                                                         array('AGR1', 'AGR2'), array('AGR3', 'AGR4'), array('AGR5', 'AGR6'),\n",
    "                                                         array('AGR5', 'AGR6'), array('AGR7', 'AGR8'), array('AGR9', 'AGR10'),\n",
    "                                                         array('CSN1', 'CSN2'), array('CSN3', 'CSN4'), array('CSN5', 'CSN6'),\n",
    "                                                         array('CSN5', 'CSN6'), array('CSN7', 'CSN8'), array('CSN9', 'CSN10'),\n",
    "                                                         array('OPN1', 'OPN2'), array('OPN3', 'OPN4'), array('OPN5', 'OPN6'),\n",
    "                                                         array('OPN5', 'OPN6'), array('OPN7', 'OPN8'), array('OPN9', 'OPN10'),\n",
    "                                                         array(col('extE').cast(IntegerType()), col('estE').cast(IntegerType()),\n",
    "                                                               col('agrE').cast(IntegerType()), col('csnE').cast(IntegerType()),\n",
    "                                                               col('opnE').cast(IntegerType()))).alias('sequence'))\n",
    "# talk\n",
    "bfps.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75203b3-e52f-49b0-b79a-fdb56663eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' fit prefix span model'''\n",
    "# fit to the data\n",
    "supp = 0.3\n",
    "patt = 10\n",
    "ps = PrefixSpan(sequenceCol='sequence', minSupport=supp, maxPatternLength=patt)\n",
    "seqs = ps.findFrequentSequentialPatterns(bfps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e0e2f-85a4-474a-8466-0d45b8882eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the frequent sequences\n",
    "seqs = seqs.withColumn('rel freq', col('freq')/bfps.count()).withColumn('maxsizes', array_max(expr('transform(sequence, x ->size(x))'))).where(col('maxsizes') > 1)\n",
    "seqs.orderBy(col('freq').desc()).show(n=20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3be340-c71e-4271-abbe-649b46e8db1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96928b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c22f013-c95e-48c7-8bda-edff5bb310e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
