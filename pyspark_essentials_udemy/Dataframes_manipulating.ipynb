{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "casual-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *#avg, count, expr\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "swiss-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 cores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.150.128:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>manipulate</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f5383219160>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize\n",
    "sc = pyspark.SparkContext()\n",
    "spark = SparkSession(sc)\n",
    "spark.sparkContext.appName = 'manipulate'\n",
    "# show the number of cores\n",
    "print('%d cores'%spark._jsc.sc().getExecutorMemoryStatus().keySet().size())\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "industrial-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "fil = '../data/youtubevideos.csv'\n",
    "schem = StructType([StructField('video_id', StringType()), StructField('trending_date', DateType()),\n",
    "                    StructField('title', StringType()), StructField('channel_title', StringType()),\n",
    "                    StructField('category_id', IntegerType()), StructField('publish_time', TimestampType()),\n",
    "                    StructField('tags', StringType()), StructField('views', IntegerType()),\n",
    "                    StructField('likes', IntegerType()), StructField('dislikes', IntegerType()),\n",
    "                    StructField('comment_count', IntegerType()), StructField('thumbnail_link', StringType()),\n",
    "                    StructField('comments_disabled', BooleanType()), StructField('ratings_disabled', BooleanType()),\n",
    "                    StructField('video_error_or_removed', BooleanType()), StructField('description', StringType())])\n",
    "# for the date / timestamp columns, could read in as string, then use withColumn to cast as dates as in\n",
    "# withColumn(col_name, to_date(col_name, date_format_string))\n",
    "# also could maybe need regexp_replace\n",
    "\n",
    "youtube = spark.read.format('csv').options(header=True, dateFormat='yy.dd.MM', timestampFormat='yyyy-MM-ddTkk:mm:ss.SSZ').schema(schem).load(fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09b71a1b-0601-42a5-80d6-1f48a4bfd076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48137 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2kyS6SvSYSE</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>CaseyNeistat</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13 17:13:01</td>\n",
       "      <td>SHANtell martin</td>\n",
       "      <td>748374</td>\n",
       "      <td>57527</td>\n",
       "      <td>2966</td>\n",
       "      <td>15954</td>\n",
       "      <td>https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ZAPwfrtAFY</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>LastWeekTonight</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13 07:30:00</td>\n",
       "      <td>\"last week tonight trump presidency\"|\"last wee...</td>\n",
       "      <td>2418783</td>\n",
       "      <td>97185</td>\n",
       "      <td>6146</td>\n",
       "      <td>12703</td>\n",
       "      <td>https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>One year after the presidential election, John...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5qpjK5DgCt4</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Rudy Mancuso</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12 19:05:24</td>\n",
       "      <td>\"racist superman\"|\"rudy\"|\"mancuso\"|\"king\"|\"bac...</td>\n",
       "      <td>3191434</td>\n",
       "      <td>146033</td>\n",
       "      <td>5339</td>\n",
       "      <td>8181</td>\n",
       "      <td>https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>puqaWrEC7tY</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>Good Mythical Morning</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13 11:00:04</td>\n",
       "      <td>\"rhett and link\"|\"gmm\"|\"good mythical morning\"...</td>\n",
       "      <td>343168</td>\n",
       "      <td>10172</td>\n",
       "      <td>666</td>\n",
       "      <td>2146</td>\n",
       "      <td>https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Today we find out if Link is a Nickelback amat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d380meD0W0M</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>nigahiga</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12 18:01:41</td>\n",
       "      <td>\"ryan\"|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"...</td>\n",
       "      <td>2095731</td>\n",
       "      <td>132235</td>\n",
       "      <td>1989</td>\n",
       "      <td>17518</td>\n",
       "      <td>https://i.ytimg.com/vi/d380meD0W0M/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I know it's been a while since we did this sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gHZ1Qz0KiKM</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>2 Weeks with iPhone X</td>\n",
       "      <td>iJustine</td>\n",
       "      <td>28</td>\n",
       "      <td>2017-11-13 19:07:23</td>\n",
       "      <td>\"ijustine\"|\"week with iPhone X\"|\"iphone x\"|\"ap...</td>\n",
       "      <td>119180</td>\n",
       "      <td>9763</td>\n",
       "      <td>511</td>\n",
       "      <td>1434</td>\n",
       "      <td>https://i.ytimg.com/vi/gHZ1Qz0KiKM/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Using the iPhone for the past two weeks -- her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39idVpFF7NQ</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>Roy Moore &amp; Jeff Sessions Cold Open - SNL</td>\n",
       "      <td>Saturday Night Live</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12 05:37:17</td>\n",
       "      <td>\"SNL\"|\"Saturday Night Live\"|\"SNL Season 43\"|\"E...</td>\n",
       "      <td>2103417</td>\n",
       "      <td>15993</td>\n",
       "      <td>2445</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://i.ytimg.com/vi/39idVpFF7NQ/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Embattled Alabama Senate candidate Roy Moore (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nc99ccSXST0</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>5 Ice Cream Gadgets put to the Test</td>\n",
       "      <td>CrazyRussianHacker</td>\n",
       "      <td>28</td>\n",
       "      <td>2017-11-12 21:50:37</td>\n",
       "      <td>\"5 Ice Cream Gadgets\"|\"Ice Cream\"|\"Cream Sandw...</td>\n",
       "      <td>817732</td>\n",
       "      <td>23663</td>\n",
       "      <td>778</td>\n",
       "      <td>3432</td>\n",
       "      <td>https://i.ytimg.com/vi/nc99ccSXST0/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Ice Cream Pint Combination Lock - http://amzn....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jr9QtXwC9vc</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>The Greatest Showman | Official Trailer 2 [HD]...</td>\n",
       "      <td>20th Century Fox</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-11-13 14:00:23</td>\n",
       "      <td>\"Trailer\"|\"Hugh Jackman\"|\"Michelle Williams\"|\"...</td>\n",
       "      <td>826059</td>\n",
       "      <td>3543</td>\n",
       "      <td>119</td>\n",
       "      <td>340</td>\n",
       "      <td>https://i.ytimg.com/vi/jr9QtXwC9vc/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Inspired by the imagination of P.T. Barnum, Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TUmyygCMMGA</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>Why the rise of the robots won’t mean the end ...</td>\n",
       "      <td>Vox</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-11-13 13:45:16</td>\n",
       "      <td>\"vox.com\"|\"vox\"|\"explain\"|\"shift change\"|\"futu...</td>\n",
       "      <td>256426</td>\n",
       "      <td>12654</td>\n",
       "      <td>1363</td>\n",
       "      <td>2368</td>\n",
       "      <td>https://i.ytimg.com/vi/TUmyygCMMGA/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>For now, at least, we have better things to wo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  2kyS6SvSYSE    2017-11-14   \n",
       "1  1ZAPwfrtAFY    2017-11-14   \n",
       "2  5qpjK5DgCt4    2017-11-14   \n",
       "3  puqaWrEC7tY    2017-11-14   \n",
       "4  d380meD0W0M    2017-11-14   \n",
       "5  gHZ1Qz0KiKM    2017-11-14   \n",
       "6  39idVpFF7NQ    2017-11-14   \n",
       "7  nc99ccSXST0    2017-11-14   \n",
       "8  jr9QtXwC9vc    2017-11-14   \n",
       "9  TUmyygCMMGA    2017-11-14   \n",
       "\n",
       "                                               title          channel_title  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat   \n",
       "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso   \n",
       "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning   \n",
       "4                           I Dare You: GOING BALD!?               nigahiga   \n",
       "5                              2 Weeks with iPhone X               iJustine   \n",
       "6          Roy Moore & Jeff Sessions Cold Open - SNL    Saturday Night Live   \n",
       "7                5 Ice Cream Gadgets put to the Test     CrazyRussianHacker   \n",
       "8  The Greatest Showman | Official Trailer 2 [HD]...       20th Century Fox   \n",
       "9  Why the rise of the robots won’t mean the end ...                    Vox   \n",
       "\n",
       "   category_id        publish_time  \\\n",
       "0           22 2017-11-13 17:13:01   \n",
       "1           24 2017-11-13 07:30:00   \n",
       "2           23 2017-11-12 19:05:24   \n",
       "3           24 2017-11-13 11:00:04   \n",
       "4           24 2017-11-12 18:01:41   \n",
       "5           28 2017-11-13 19:07:23   \n",
       "6           24 2017-11-12 05:37:17   \n",
       "7           28 2017-11-12 21:50:37   \n",
       "8            1 2017-11-13 14:00:23   \n",
       "9           25 2017-11-13 13:45:16   \n",
       "\n",
       "                                                tags    views   likes  \\\n",
       "0                                    SHANtell martin   748374   57527   \n",
       "1  \"last week tonight trump presidency\"|\"last wee...  2418783   97185   \n",
       "2  \"racist superman\"|\"rudy\"|\"mancuso\"|\"king\"|\"bac...  3191434  146033   \n",
       "3  \"rhett and link\"|\"gmm\"|\"good mythical morning\"...   343168   10172   \n",
       "4  \"ryan\"|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"...  2095731  132235   \n",
       "5  \"ijustine\"|\"week with iPhone X\"|\"iphone x\"|\"ap...   119180    9763   \n",
       "6  \"SNL\"|\"Saturday Night Live\"|\"SNL Season 43\"|\"E...  2103417   15993   \n",
       "7  \"5 Ice Cream Gadgets\"|\"Ice Cream\"|\"Cream Sandw...   817732   23663   \n",
       "8  \"Trailer\"|\"Hugh Jackman\"|\"Michelle Williams\"|\"...   826059    3543   \n",
       "9  \"vox.com\"|\"vox\"|\"explain\"|\"shift change\"|\"futu...   256426   12654   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0      2966          15954  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
       "1      6146          12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
       "2      5339           8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
       "3       666           2146  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
       "4      1989          17518  https://i.ytimg.com/vi/d380meD0W0M/default.jpg   \n",
       "5       511           1434  https://i.ytimg.com/vi/gHZ1Qz0KiKM/default.jpg   \n",
       "6      2445           1970  https://i.ytimg.com/vi/39idVpFF7NQ/default.jpg   \n",
       "7       778           3432  https://i.ytimg.com/vi/nc99ccSXST0/default.jpg   \n",
       "8       119            340  https://i.ytimg.com/vi/jr9QtXwC9vc/default.jpg   \n",
       "9      1363           2368  https://i.ytimg.com/vi/TUmyygCMMGA/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "5              False             False                   False   \n",
       "6              False             False                   False   \n",
       "7              False             False                   False   \n",
       "8              False             False                   False   \n",
       "9              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...  \n",
       "1  One year after the presidential election, John...  \n",
       "2  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...  \n",
       "3  Today we find out if Link is a Nickelback amat...  \n",
       "4  I know it's been a while since we did this sho...  \n",
       "5  Using the iPhone for the past two weeks -- her...  \n",
       "6  Embattled Alabama Senate candidate Roy Moore (...  \n",
       "7  Ice Cream Pint Combination Lock - http://amzn....  \n",
       "8  Inspired by the imagination of P.T. Barnum, Th...  \n",
       "9  For now, at least, we have better things to wo...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# talk\n",
    "print('%d rows'%youtube.count())\n",
    "display(youtube.limit(10).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d28d02d-4c99-4fbc-8210-a8ef940f349f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------------------+--------------------+-----------+-------------------+--------------------+-------+------+--------+-------------+--------------------+-----------------+----------------+----------------------+--------------------+\n",
      "|   video_id|trending_date|               title|       channel_title|category_id|       publish_time|                tags|  views| likes|dislikes|comment_count|      thumbnail_link|comments_disabled|ratings_disabled|video_error_or_removed|         description|\n",
      "+-----------+-------------+--------------------+--------------------+-----------+-------------------+--------------------+-------+------+--------+-------------+--------------------+-----------------+----------------+----------------------+--------------------+\n",
      "|2kyS6SvSYSE|   2017-11-14|WE WANT TO TALK A...|        CaseyNeistat|         22|2017-11-13 17:13:01|     SHANtell martin| 748374| 57527|    2966|        15954|https://i.ytimg.c...|            false|           false|                 false|SHANTELL'S CHANNE...|\n",
      "|1ZAPwfrtAFY|   2017-11-14|The Trump Preside...|     LastWeekTonight|         24|2017-11-13 07:30:00|\"last week tonigh...|2418783| 97185|    6146|        12703|https://i.ytimg.c...|            false|           false|                 false|One year after th...|\n",
      "|5qpjK5DgCt4|   2017-11-14|Racist Superman |...|        Rudy Mancuso|         23|2017-11-12 19:05:24|\"racist superman\"...|3191434|146033|    5339|         8181|https://i.ytimg.c...|            false|           false|                 false|WATCH MY PREVIOUS...|\n",
      "|puqaWrEC7tY|   2017-11-14|Nickelback Lyrics...|Good Mythical Mor...|         24|2017-11-13 11:00:04|\"rhett and link\"|...| 343168| 10172|     666|         2146|https://i.ytimg.c...|            false|           false|                 false|Today we find out...|\n",
      "|d380meD0W0M|   2017-11-14|I Dare You: GOING...|            nigahiga|         24|2017-11-12 18:01:41|\"ryan\"|\"higa\"|\"hi...|2095731|132235|    1989|        17518|https://i.ytimg.c...|            false|           false|                 false|I know it's been ...|\n",
      "|gHZ1Qz0KiKM|   2017-11-14|2 Weeks with iPho...|            iJustine|         28|2017-11-13 19:07:23|\"ijustine\"|\"week ...| 119180|  9763|     511|         1434|https://i.ytimg.c...|            false|           false|                 false|Using the iPhone ...|\n",
      "|39idVpFF7NQ|   2017-11-14|Roy Moore & Jeff ...| Saturday Night Live|         24|2017-11-12 05:37:17|\"SNL\"|\"Saturday N...|2103417| 15993|    2445|         1970|https://i.ytimg.c...|            false|           false|                 false|Embattled Alabama...|\n",
      "|nc99ccSXST0|   2017-11-14|5 Ice Cream Gadge...|  CrazyRussianHacker|         28|2017-11-12 21:50:37|\"5 Ice Cream Gadg...| 817732| 23663|     778|         3432|https://i.ytimg.c...|            false|           false|                 false|Ice Cream Pint Co...|\n",
      "|jr9QtXwC9vc|   2017-11-14|The Greatest Show...|    20th Century Fox|          1|2017-11-13 14:00:23|\"Trailer\"|\"Hugh J...| 826059|  3543|     119|          340|https://i.ytimg.c...|            false|           false|                 false|Inspired by the i...|\n",
      "|TUmyygCMMGA|   2017-11-14|Why the rise of t...|                 Vox|         25|2017-11-13 13:45:16|\"vox.com\"|\"vox\"|\"...| 256426| 12654|    1363|         2368|https://i.ytimg.c...|            false|           false|                 false|For now, at least...|\n",
      "|9wRQljFNDW8|   2017-11-14|Dion Lewis' 103-Y...|                 NFL|         17|2017-11-13 02:05:26|\"NFL\"|\"Football\"|...|  81377|   655|      25|          177|https://i.ytimg.c...|            false|           false|                 false|New England Patri...|\n",
      "|VifQlJit6A0|   2017-11-14|(SPOILERS) 'Shiva...|                 amc|         24|2017-11-13 03:00:00|\"The Walking Dead...| 104578|  1576|     303|         1279|https://i.ytimg.c...|            false|           false|                 false|Shiva arrives jus...|\n",
      "|5E4ZBSInqUU|   2017-11-14|Marshmello - Bloc...|          marshmello|         10|2017-11-13 17:00:00|\"marshmello\"|\"blo...| 687582|114188|    1333|         8371|https://i.ytimg.c...|            false|           false|                 false|WATCH SILENCE MUS...|\n",
      "|GgVmn66oK_A|   2017-11-14|Which Countries A...|       NowThis World|         25|2017-11-12 14:00:00|\"nowthis\"|\"nowthi...| 544770|  7848|    1171|         3981|https://i.ytimg.c...|            false|           false|                 false|The world at larg...|\n",
      "|TaTleo4cOs8|   2017-11-14|SHOPPING FOR NEW ...|     The king of DIY|         15|2017-11-12 18:30:01|\"shopping for new...| 207532|  7473|     246|         2120|https://i.ytimg.c...|            false|           false|                 false|Today we go shopp...|\n",
      "|kgaO45SyaO4|   2017-11-14|    The New SpotMini|      BostonDynamics|         28|2017-11-13 20:09:58|\"Robots\"|\"Boston ...|  75752|  9419|      52|         1230|https://i.ytimg.c...|            false|           false|                 false|For more informat...|\n",
      "|ZAQs-ctOqXQ|   2017-11-14|One Change That W...|             Cracked|         23|2017-11-12 17:00:05|\"pacific rim\"|\"pa...| 295639|  8011|     638|         1256|https://i.ytimg.c...|            false|           false|                 false|Pacific Rim was s...|\n",
      "|YVfyYrEmzgM|   2017-11-14|How does your bod...|              TED-Ed|         27|2017-11-13 16:00:07|\"TED\"|\"TED-Ed\"|\"T...|  78044|  5398|      53|          385|https://i.ytimg.c...|            false|           false|                 false|Check out our Pat...|\n",
      "|eNSN6qet1kE|   2017-11-14|HomeMade Electric...|         PeterSripol|         28|2017-11-13 15:30:17|\"ultralight\"|\"air...|  97007| 11963|      36|         2211|https://i.ytimg.c...|            false|           false|                 false|aaaannnd now to f...|\n",
      "|B5HORANmzHw|   2017-11-14|Founding An Inbre...|             SciShow|         27|2017-11-12 22:00:01|\"SciShow\"|\"scienc...| 223871|  8421|     191|         1214|https://i.ytimg.c...|            false|           false|                 false|Thanks to 23AndMe...|\n",
      "+-----------+-------------+--------------------+--------------------+-----------+-------------------+--------------------+-------+------+--------+-------------+--------------------+-----------------+----------------+----------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "youtube.select('*').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "937b068b-b6cf-4b8f-9f43-51dd6cb5f559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>trimmed</th>\n",
       "      <th>ltrimmed</th>\n",
       "      <th>rtrimmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE   \n",
       "1  The Trump Presidency: Last Week Tonight with J...   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...   \n",
       "3                   Nickelback Lyrics: Real or Fake?   \n",
       "4                           I Dare You: GOING BALD!?   \n",
       "\n",
       "                                             trimmed  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE   \n",
       "1  The Trump Presidency: Last Week Tonight with J...   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...   \n",
       "3                   Nickelback Lyrics: Real or Fake?   \n",
       "4                           I Dare You: GOING BALD!?   \n",
       "\n",
       "                                            ltrimmed  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE   \n",
       "1  The Trump Presidency: Last Week Tonight with J...   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...   \n",
       "3                   Nickelback Lyrics: Real or Fake?   \n",
       "4                           I Dare You: GOING BALD!?   \n",
       "\n",
       "                                            rtrimmed  \n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE  \n",
       "1  The Trump Presidency: Last Week Tonight with J...  \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...  \n",
       "3                   Nickelback Lyrics: Real or Fake?  \n",
       "4                           I Dare You: GOING BALD!?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# trimming\n",
    "trimmed = youtube.select('title', trim('title').alias('trimmed'), ltrim('title').alias('ltrimmed'), rtrim('title').alias('rtrimmed')).toPandas()\n",
    "display(trimmed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "232b4f6b-589f-46eb-8cfc-cc789bfe7fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------+\n",
      "| Likes|Dislikes|NetPref|\n",
      "+------+--------+-------+\n",
      "| 57527|    2966|    :-)|\n",
      "| 97185|    6146|    :-)|\n",
      "|146033|    5339|    :-)|\n",
      "| 10172|     666|    :-)|\n",
      "|132235|    1989|    :-)|\n",
      "|  9763|     511|    :-)|\n",
      "| 15993|    2445|    :-)|\n",
      "| 23663|     778|    :-)|\n",
      "|  3543|     119|    :-)|\n",
      "| 12654|    1363|    :-)|\n",
      "+------+--------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------+-----+\n",
      "|NetPref|count|\n",
      "+-------+-----+\n",
      "|    :-(|  576|\n",
      "|    :-)|40192|\n",
      "|    :-|| 7369|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# case when\n",
    "lkd = youtube.select('Likes', 'Dislikes', when(col('Likes') > col('Dislikes'), ':-)')\\\n",
    "                     .when(col('Likes') < col('Dislikes'), ':-(').otherwise(':-|').alias('NetPref'))\n",
    "lkd.show(10)\n",
    "lkd.select('NetPref').groupBy('NetPref').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9dd9cec-0002-4e02-a7bb-e6f331030b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----------------------------------------------------------------+----------------------------------------------------------------------------------+\n",
      "|channel_title        |title                                                            |alltitle                                                                          |\n",
      "+---------------------+-----------------------------------------------------------------+----------------------------------------------------------------------------------+\n",
      "|CaseyNeistat         |WE WANT TO TALK ABOUT OUR MARRIAGE                               |CaseyNeistat-WE WANT TO TALK ABOUT OUR MARRIAGE                                   |\n",
      "|LastWeekTonight      |The Trump Presidency: Last Week Tonight with John Oliver (HBO)   |LastWeekTonight-The Trump Presidency: Last Week Tonight with John Oliver (HBO)    |\n",
      "|Rudy Mancuso         |Racist Superman | Rudy Mancuso, King Bach & Lele Pons            |Rudy Mancuso-Racist Superman | Rudy Mancuso, King Bach & Lele Pons                |\n",
      "|Good Mythical Morning|Nickelback Lyrics: Real or Fake?                                 |Good Mythical Morning-Nickelback Lyrics: Real or Fake?                            |\n",
      "|nigahiga             |I Dare You: GOING BALD!?                                         |nigahiga-I Dare You: GOING BALD!?                                                 |\n",
      "|iJustine             |2 Weeks with iPhone X                                            |iJustine-2 Weeks with iPhone X                                                    |\n",
      "|Saturday Night Live  |Roy Moore & Jeff Sessions Cold Open - SNL                        |Saturday Night Live-Roy Moore & Jeff Sessions Cold Open - SNL                     |\n",
      "|CrazyRussianHacker   |5 Ice Cream Gadgets put to the Test                              |CrazyRussianHacker-5 Ice Cream Gadgets put to the Test                            |\n",
      "|20th Century Fox     |The Greatest Showman | Official Trailer 2 [HD] | 20th Century FOX|20th Century Fox-The Greatest Showman | Official Trailer 2 [HD] | 20th Century FOX|\n",
      "|Vox                  |Why the rise of the robots won’t mean the end of work            |Vox-Why the rise of the robots won’t mean the end of work                         |\n",
      "+---------------------+-----------------------------------------------------------------+----------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# concat\n",
    "youtube.select('channel_title', 'title', concat_ws('-', col('channel_title'), col('title')).alias('alltitle')).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "970d28ac-6374-404f-b8ab-e4331ec27524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+--------------------+\n",
      "|trending_date|year(trending_date)|month(trending_date)|\n",
      "+-------------+-------------------+--------------------+\n",
      "|   2017-11-14|               2017|                  11|\n",
      "|   2017-11-14|               2017|                  11|\n",
      "|   2017-11-14|               2017|                  11|\n",
      "|   2017-11-14|               2017|                  11|\n",
      "|   2017-11-14|               2017|                  11|\n",
      "+-------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "youtube.select('trending_date', year('trending_date'), month('trending_date')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edb0c449-7403-492f-8419-c285edb1a19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+-------------+-------------------+-----------+\n",
      "|title                           |trending_date|publish_time       |TimeToTrend|\n",
      "+--------------------------------+-------------+-------------------+-----------+\n",
      "|Budweiser - Original Whazzup? ad|2018-02-05   |2006-07-23 09:24:11|4215       |\n",
      "|Kramer vs Kramer-Clou Scene     |2018-01-09   |2008-04-05 19:22:40|3566       |\n",
      "|Kramer vs Kramer-Clou Scene     |2018-01-08   |2008-04-05 19:22:40|3565       |\n",
      "|Kramer vs Kramer-Clou Scene     |2018-01-07   |2008-04-05 19:22:40|3564       |\n",
      "|Kramer vs Kramer-Clou Scene     |2018-01-06   |2008-04-05 19:22:40|3563       |\n",
      "|Behind The Sounds: That's Not Me|2017-11-28   |2008-06-17 01:07:56|3451       |\n",
      "|Behind The Sounds: That's Not Me|2017-11-27   |2008-06-17 01:07:56|3450       |\n",
      "|Behind The Sounds: That's Not Me|2017-11-26   |2008-06-17 01:07:56|3449       |\n",
      "|Behind The Sounds: That's Not Me|2017-11-25   |2008-06-17 01:07:56|3448       |\n",
      "|SAOIRSE RONAN - MORONIC (IRONIC)|2017-11-28   |2008-08-07 13:16:58|3400       |\n",
      "+--------------------------------+-------------+-------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "youtube.select('title', 'trending_date', 'publish_time', datediff(col('trending_date'), col('publish_time')).alias('TimeToTrend'))\\\n",
    "    .orderBy(col('TimeToTrend').desc()).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41c89b53-0177-470a-9e2d-f1e8506f96e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------+------------------------------------------------------------------------------+\n",
      "|title                                                            |parsedTitle                                                                   |\n",
      "+-----------------------------------------------------------------+------------------------------------------------------------------------------+\n",
      "|WE WANT TO TALK ABOUT OUR MARRIAGE                               |[we, want, to, talk, about, our, marriage]                                    |\n",
      "|The Trump Presidency: Last Week Tonight with John Oliver (HBO)   |[the, trump, presidency:, last, week, tonight, with, john, oliver, (hbo)]     |\n",
      "|Racist Superman | Rudy Mancuso, King Bach & Lele Pons            |[racist, superman, |, rudy, mancuso,, king, bach, &, lele, pons]              |\n",
      "|Nickelback Lyrics: Real or Fake?                                 |[nickelback, lyrics:, real, or, fake?]                                        |\n",
      "|I Dare You: GOING BALD!?                                         |[i, dare, you:, going, bald!?]                                                |\n",
      "|2 Weeks with iPhone X                                            |[2, weeks, with, iphone, x]                                                   |\n",
      "|Roy Moore & Jeff Sessions Cold Open - SNL                        |[roy, moore, &, jeff, sessions, cold, open, -, snl]                           |\n",
      "|5 Ice Cream Gadgets put to the Test                              |[5, ice, cream, gadgets, put, to, the, test]                                  |\n",
      "|The Greatest Showman | Official Trailer 2 [HD] | 20th Century FOX|[the, greatest, showman, |, official, trailer, 2, [hd], |, 20th, century, fox]|\n",
      "|Why the rise of the robots won’t mean the end of work            |[why, the, rise, of, the, robots, won’t, mean, the, end, of, work]            |\n",
      "+-----------------------------------------------------------------+------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titleWords = youtube.select('title', split(lower(col('title')), ' ').alias('parsedTitle'))\n",
    "titleWords.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3a52834-f6cf-488a-935d-a29999dcacf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------+----+\n",
      "|title                                                                                          |aca |\n",
      "+-----------------------------------------------------------------------------------------------+----+\n",
      "|The Trump Presidency: Last Week Tonight with John Oliver (HBO)                                 |true|\n",
      "|The Trump Presidency: Last Week Tonight with John Oliver (HBO)                                 |true|\n",
      "|The Trump Presidency: Last Week Tonight with John Oliver (HBO)                                 |true|\n",
      "|Donald Trump makes ASEAN handshake photo op go awry                                            |true|\n",
      "|The Trump Presidency: Last Week Tonight with John Oliver (HBO)                                 |true|\n",
      "|Donald Trump makes ASEAN handshake photo op go awry                                            |true|\n",
      "|President Donald Trump Makes Statement From White House On Asia Trip (Full) | NBC News         |true|\n",
      "|The Trump Presidency: Last Week Tonight with John Oliver (HBO)                                 |true|\n",
      "|Donald Trump makes ASEAN handshake photo op go awry                                            |true|\n",
      "|President Donald Trump Makes Statement From White House On Asia Trip (Full) | NBC News         |true|\n",
      "|The Trump Presidency: Last Week Tonight with John Oliver (HBO)                                 |true|\n",
      "|President Donald Trump Makes Statement From White House On Asia Trip (Full) | NBC News         |true|\n",
      "|The Trump Presidency: Last Week Tonight with John Oliver (HBO)                                 |true|\n",
      "|Trump pardons Thanksgiving turkey                                                              |true|\n",
      "|President Donald Trump Pardons His First Thanksgiving Turkey At White House Ceremony | NBC News|true|\n",
      "|Trump Breaks Silence On Roy Moore And Offers De-Facto Endorsement                              |true|\n",
      "|Trump Backs Roy Moore; Charlie Rose Fired for Sexual Harassment: A Closer Look                 |true|\n",
      "|President Donald Trump Pardons His First Thanksgiving Turkey At White House Ceremony | NBC News|true|\n",
      "|Trump Backs Roy Moore; Charlie Rose Fired for Sexual Harassment: A Closer Look                 |true|\n",
      "|President Donald Trump Pardons His First Thanksgiving Turkey At White House Ceremony | NBC News|true|\n",
      "+-----------------------------------------------------------------------------------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titleWords.select('title', array_contains(col('parsedTitle'), 'trump').alias('aca')).where(col('aca')==True).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f2fec90-f614-495b-a318-565632e5660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------+----------------------------------------------------------------------+\n",
      "|title                                                            |reparsed                                                              |\n",
      "+-----------------------------------------------------------------+----------------------------------------------------------------------+\n",
      "|WE WANT TO TALK ABOUT OUR MARRIAGE                               |[we, want, to, talk, about, our, marriage]                            |\n",
      "|The Trump Presidency: Last Week Tonight with John Oliver (HBO)   |[trump, presidency:, last, week, tonight, with, john, oliver, (hbo)]  |\n",
      "|Racist Superman | Rudy Mancuso, King Bach & Lele Pons            |[racist, superman, |, rudy, mancuso,, king, bach, &, lele, pons]      |\n",
      "|Nickelback Lyrics: Real or Fake?                                 |[nickelback, lyrics:, real, or, fake?]                                |\n",
      "|I Dare You: GOING BALD!?                                         |[i, dare, you:, going, bald!?]                                        |\n",
      "|2 Weeks with iPhone X                                            |[2, weeks, with, iphone, x]                                           |\n",
      "|Roy Moore & Jeff Sessions Cold Open - SNL                        |[roy, moore, &, jeff, sessions, cold, open, -, snl]                   |\n",
      "|5 Ice Cream Gadgets put to the Test                              |[5, ice, cream, gadgets, put, to, test]                               |\n",
      "|The Greatest Showman | Official Trailer 2 [HD] | 20th Century FOX|[greatest, showman, |, official, trailer, 2, [hd], 20th, century, fox]|\n",
      "|Why the rise of the robots won’t mean the end of work            |[why, rise, of, robots, won’t, mean, end, work]                       |\n",
      "+-----------------------------------------------------------------+----------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titleWords.select('title', array_distinct(array_remove(col('parsedTitle'), 'the')).alias('reparsed')).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "61058073-4e99-44d3-a207-6397896a73fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pysaprk UDF, which can get farmed out to all workers on the cluster\n",
    "def squareCol(acol):\n",
    "    if (acol is None) or np.isnan(acol):\n",
    "        res = 0\n",
    "    else:\n",
    "        res = int(acol**2)\n",
    "    return res\n",
    "squareColUDF = udf(lambda x: squareCol(x), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "304221f4-9704-4e01-9fa6-4849602050a9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o470.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 47.0 failed 1 times, most recent failure: Lost task 0.0 in stage 47.0 (TID 238) (192.168.150.128 executor driver): org.apache.spark.SparkException: \nBad data in pyspark.daemon's standard output. Invalid port number:\n  458961458 (0x1b5b3232)\nPython command to execute the daemon was:\n  ipython3 -m pyspark.daemon\nCheck that you don't have any unexpected modules or libraries in\nyour PYTHONPATH:\n  /home/ahowe42/spark-3.1.1-bin-hadoop2.7/python/lib/pyspark.zip:/home/ahowe42/spark-3.1.1-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip:/home/ahowe42/spark-3.1.1-bin-hadoop2.7/jars/spark-core_2.12-3.1.1.jar:/home/ahowe42/anaconda3/bin\nAlso, check if you have a sitecustomize.py module in your python path,\nor in your python installation, that is printing to standard output\n\tat org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:238)\n\tat org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:132)\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:105)\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:70)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:130)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2223)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2242)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:472)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:425)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3696)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:772)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2929)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:301)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:338)\n\tat sun.reflect.GeneratedMethodAccessor92.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: \nBad data in pyspark.daemon's standard output. Invalid port number:\n  458961458 (0x1b5b3232)\nPython command to execute the daemon was:\n  ipython3 -m pyspark.daemon\nCheck that you don't have any unexpected modules or libraries in\nyour PYTHONPATH:\n  /home/ahowe42/spark-3.1.1-bin-hadoop2.7/python/lib/pyspark.zip:/home/ahowe42/spark-3.1.1-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip:/home/ahowe42/spark-3.1.1-bin-hadoop2.7/jars/spark-core_2.12-3.1.1.jar:/home/ahowe42/anaconda3/bin\nAlso, check if you have a sitecustomize.py module in your python path,\nor in your python installation, that is printing to standard output\n\tat org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:238)\n\tat org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:132)\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:105)\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:70)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:130)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-a49eb9b4416e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myoutube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'likes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquareColUDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'likes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'squaredLikes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'likes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misNotNull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \"\"\"\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.1.1-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.1.1-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o470.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 47.0 failed 1 times, most recent failure: Lost task 0.0 in stage 47.0 (TID 238) (192.168.150.128 executor driver): org.apache.spark.SparkException: \nBad data in pyspark.daemon's standard output. Invalid port number:\n  458961458 (0x1b5b3232)\nPython command to execute the daemon was:\n  ipython3 -m pyspark.daemon\nCheck that you don't have any unexpected modules or libraries in\nyour PYTHONPATH:\n  /home/ahowe42/spark-3.1.1-bin-hadoop2.7/python/lib/pyspark.zip:/home/ahowe42/spark-3.1.1-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip:/home/ahowe42/spark-3.1.1-bin-hadoop2.7/jars/spark-core_2.12-3.1.1.jar:/home/ahowe42/anaconda3/bin\nAlso, check if you have a sitecustomize.py module in your python path,\nor in your python installation, that is printing to standard output\n\tat org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:238)\n\tat org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:132)\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:105)\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:70)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:130)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2223)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2242)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:472)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:425)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3696)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:772)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2929)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:301)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:338)\n\tat sun.reflect.GeneratedMethodAccessor92.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: \nBad data in pyspark.daemon's standard output. Invalid port number:\n  458961458 (0x1b5b3232)\nPython command to execute the daemon was:\n  ipython3 -m pyspark.daemon\nCheck that you don't have any unexpected modules or libraries in\nyour PYTHONPATH:\n  /home/ahowe42/spark-3.1.1-bin-hadoop2.7/python/lib/pyspark.zip:/home/ahowe42/spark-3.1.1-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip:/home/ahowe42/spark-3.1.1-bin-hadoop2.7/jars/spark-core_2.12-3.1.1.jar:/home/ahowe42/anaconda3/bin\nAlso, check if you have a sitecustomize.py module in your python path,\nor in your python installation, that is printing to standard output\n\tat org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:238)\n\tat org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:132)\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:105)\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:70)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:130)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "youtube.select('likes', squareColUDF('likes').alias('squaredLikes')).where(col('likes').isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "accomplished-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9a11f-c85f-40fa-9308-7e592a9bc774",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
