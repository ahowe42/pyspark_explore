{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *#avg, count, expr\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString, RegexTokenizer,\\\n",
    "    StopWordsRemover, Word2Vec, CountVectorizer, IDF, HashingTF, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "sc = pyspark.SparkContext()\n",
    "spark = SparkSession(sc)\n",
    "spark.sparkContext.appName = 'nlpHW'\n",
    "# show the number of cores\n",
    "print('%d cores'%spark._jsc.sc().getExecutorMemoryStatus().keySet().size())\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "fil = '../../data/fake_job_postings.csv'\n",
    "schem = StructType([StructField('job_id', IntegerType()), StructField('title', StringType()),\n",
    "                    StructField('location', StringType()), StructField('department', StringType()),\n",
    "                    StructField('salary_range', StringType()), StructField('company_profile', StringType()),\n",
    "                    StructField('description', StringType()), StructField('requirements', StringType()),\n",
    "                    StructField('benefits', StringType()), StructField('telecommuting', IntegerType()),\n",
    "                    StructField('has_company_logo', IntegerType()), StructField('has_questions', IntegerType()),\n",
    "                    StructField('employment_type', StringType()), StructField('required_experience', StringType()),\n",
    "                    StructField('required_education', StringType()), StructField('industry', StringType()),\n",
    "                    StructField('function', StringType()), StructField('fraudulent', IntegerType())])\n",
    "jobs = spark.read.format('csv').options(header=True).schema(schem).load(fil)\n",
    "\n",
    "# talk\n",
    "cnt = jobs.count()\n",
    "print('%d records'%cnt)\n",
    "display(jobs.limit(10).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6b5999-bbca-4da0-a9cc-ece3ca06c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catenate together the text fields\n",
    "concatCols = [colm.name for colm in jobs.schema if colm.dataType is StringType()]\n",
    "print('Concatenating %s'%concatCols)\n",
    "jobs = jobs.select('job_id', 'fraudulent', 'telecommuting', 'has_company_logo', 'has_questions',\\\n",
    "                   concat_ws(' ', *concatCols).alias('text'))\n",
    "# talk\n",
    "display(jobs.limit(10).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280c3b8-344e-4bab-bdf4-247d7a9bdada",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' handle missing values '''\n",
    "# check for missing values\n",
    "nullCounts = {colm:jobs.select(colm).where(col(colm).isNull()).count() for colm in jobs.columns}\n",
    "nullCounts = {colm:(ncnt, ncnt/cnt) for (colm, ncnt) in nullCounts.items()}\n",
    "nullCountsDF = pd.DataFrame(nullCounts).T.reset_index(drop=False).sort_values(1, ascending=False)\n",
    "nullCountsDF.columns = ['Column', 'Freq.', 'Rel. Freq.']\n",
    "nullCountsDF = nullCountsDF.merge(pd.DataFrame([[colm.name, colm.dataType] for colm in jobs.schema], columns=['Column', 'Type']),\n",
    "                                how='inner', on=['Column'])\n",
    "\n",
    "# talk\n",
    "display(nullCountsDF)\n",
    "\n",
    "# drop mostly null columns\n",
    "dropUs = nullCountsDF.loc[nullCountsDF['Rel. Freq.'] >.06, 'Column'].values.tolist()\n",
    "print('Dropping %s'%dropUs)\n",
    "\n",
    "# remove too-empty columns and the remaining nulls\n",
    "jobs = jobs.drop(*dropUs).dropna(how='any')\n",
    "\n",
    "# talk some more\n",
    "print('%d records'%jobs.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab9d635-fc9a-481c-811b-e5a9e902d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ensure fraudulent is only 0 or 1 '''\n",
    "# count by state\n",
    "jobs.groupBy('fraudulent').count().orderBy(col('count').desc()).show()\n",
    "\n",
    "# remove the bad rows if any\n",
    "jobs = jobs.where(col('fraudulent').isin(0, 1)).withColumnRenamed('fraudulent', 'label')\n",
    "\n",
    "# talk\n",
    "print('%d records'%jobs.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f46ed1-f62c-430f-8886-f44ba7da95de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' get rid of\n",
    "urls\n",
    "non-alphanumeric or whitespace chars\n",
    "get rid of multiplied spaces\n",
    "'''\n",
    "# get the regexp for urls\n",
    "with open('url_regex.txt', 'rt') as f:\n",
    "    urlRE = f.readline().strip()\n",
    "\n",
    "jobs = jobs.select('job_id', 'label', 'telecommuting', 'has_company_logo', 'has_questions',\n",
    "                   regexp_replace(col('text'), urlRE, ' ').alias('text'))\\\n",
    "    .withColumn('text', regexp_replace(col('text'), '[^A-Za-z0-9]', ' '))\\\n",
    "    .withColumn('text', regexp_replace(col('text'), ' +', ' '))\n",
    "\n",
    "# talk\n",
    "jobs.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a0828b-51dd-4940-87ce-2c7660cf32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the boolean flags into an array\n",
    "jobs = jobs.select('job_id', 'label', array('telecommuting', 'has_company_logo', 'has_questions').alias('bools'), 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65bd8dc-d82a-409e-a339-74a96dad47eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' final words pre-processing '''\n",
    "# tokenizer\n",
    "toker = RegexTokenizer(inputCol='text', outputCol='words', pattern='\\\\W', toLowercase=True)\n",
    "# stopper\n",
    "stop = StopWordsRemover(inputCol=toker.getOutputCol(), outputCol='fewer_words')\n",
    "\n",
    "# pipeline\n",
    "featEngine = Pipeline(stages=[toker, stop]).fit(jobs)\n",
    "jobs = featEngine.transform(jobs).select('job_id', 'label', 'bools', 'fewer_words')\n",
    "\n",
    "# talk\n",
    "jobs.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8256f9c0-b536-4304-a7be-e0cdd320b47f",
   "metadata": {},
   "source": [
    "### NLP Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a23714-c689-4eff-a81a-31d6a3905b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the hashing term frequency processor\n",
    "words = 256 # should be a power of 2\n",
    "htf = HashingTF(inputCol='fewer_words', outputCol='features', numFeatures=words)\n",
    "jobsTF = htf.transform(jobs).drop('fewer_words')\n",
    "jobsTF.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af3f96f-df69-44e0-a5b8-50a77e6f43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try tfidf - requires term frequencies input\n",
    "idf = IDF(inputCol='tf', outputCol='features')\n",
    "idfmod = idf.fit(jobsTF.withColumnRenamed('features', 'tf'))\n",
    "jobsTFIDF = idfmod.transform(jobsTF.withColumnRenamed('features', 'tf')).drop('tf')\n",
    "jobsTFIDF.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff044ef-0d13-4508-849d-3b238c1509b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try word2vec\n",
    "vecLen = 10\n",
    "w2v = Word2Vec(vectorSize=vecLen, minCount=1, inputCol='fewer_words', outputCol='features')\n",
    "w2vmod = w2v.fit(jobs)\n",
    "jobsW2V = w2vmod.transform(jobs).drop('fewer_words')\n",
    "jobsW2V.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bef0e3-7f38-4339-9c43-dd0e1f9a2a5f",
   "metadata": {},
   "source": [
    "### Try to fit classifiction models to these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b809781-b9f1-4f4d-a644-f7e51c70da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPerc = 0.7\n",
    "randSeed = 20180619\n",
    "subsample = {0:0.25, 1:1.0}\n",
    "acc = MulticlassClassificationEvaluator(metricName='truePositiveRateByLabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b54671-3ded-42c6-a8a3-e5215f418c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' term frequency data '''\n",
    "# put the boolean and word vectors together\n",
    "vecass = VectorAssembler(inputCols=['label', 'feat'], outputCol='features')\n",
    "jobsTF = vecass.transform(jobsTF.withColumnRenamed('features', 'feat')).drop('bools', 'feat')\n",
    "\n",
    "# resample by the label, then split for cross-val\n",
    "trn, tst = jobsTF.select('job_id', 'label', 'features').sampleBy('label', fractions=subsample, seed=randSeed)\\\n",
    "    .randomSplit([trainPerc, 1.0 - trainPerc], seed=randSeed)\n",
    "\n",
    "# fit a random forest\n",
    "estim = RandomForestClassifier(numTrees=20)\n",
    "fitModel = estim.fit(trn)\n",
    "trainRes = fitModel.evaluate(trn)\n",
    "trainAcc = acc.evaluate(trainRes.predictions)\n",
    "\n",
    "# now evaluate test accuracy\n",
    "testRes = fitModel.transform(tst)\n",
    "testAcc = acc.evaluate(testRes)\n",
    "\n",
    "print('Train True Positive Rate = %0.5f, Test True Positive Rate = %0.5f'%(trainAcc, testAcc))\n",
    "\n",
    "# show the results for fraudulents\n",
    "print('Training')\n",
    "trainRes.predictions.select('job_id', 'label', 'prediction').where(col('label')==1).show(10)\n",
    "print('Testing')\n",
    "testRes.select('job_id', 'label', 'prediction').where(col('label')==1).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb082f8-805d-481c-b902-49a29d85df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TFIDF data '''\n",
    "# put the boolean and word vectors together\n",
    "vecass = VectorAssembler(inputCols=['label', 'feat'], outputCol='features')\n",
    "jobsTFIDF = vecass.transform(jobsTFIDF.withColumnRenamed('features', 'feat')).drop('bools', 'feat')\n",
    "\n",
    "# resample by the label, then split for cross-val\n",
    "trn, tst = jobsTFIDF.select('job_id', 'label', 'features').sampleBy('label', fractions=subsample, seed=randSeed)\\\n",
    "    .randomSplit([trainPerc, 1.0 - trainPerc], seed=randSeed)\n",
    "\n",
    "# fit a random forest\n",
    "estim = RandomForestClassifier(numTrees=20)\n",
    "fitModel = estim.fit(trn)\n",
    "trainRes = fitModel.evaluate(trn)\n",
    "trainAcc = acc.evaluate(trainRes.predictions)\n",
    "\n",
    "# now evaluate test accuracy\n",
    "testRes = fitModel.transform(tst)\n",
    "testAcc = acc.evaluate(testRes)\n",
    "\n",
    "print('Train True Positive Rate = %0.5f, Test True Positive Rate = %0.5f'%(trainAcc, testAcc))\n",
    "\n",
    "# show the results for fraudulents\n",
    "print('Training')\n",
    "trainRes.predictions.select('job_id', 'label', 'prediction').where(col('label')==1).show(10)\n",
    "print('Testing')\n",
    "testRes.select('job_id', 'label', 'prediction').where(col('label')==1).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59eb105-5a15-416d-9be3-4434c3e24ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' word2vec data '''\n",
    "# put the boolean and word vectors together\n",
    "vecass = VectorAssembler(inputCols=['label', 'feat'], outputCol='features')\n",
    "jobsW2V = vecass.transform(jobsW2V.withColumnRenamed('features', 'feat')).drop('bools', 'feat')\n",
    "\n",
    "# resample by the label, then split for cross-val\n",
    "trn, tst = jobsW2V.select('job_id', 'label', 'features').sampleBy('label', fractions=subsample, seed=randSeed)\\\n",
    "    .randomSplit([trainPerc, 1.0 - trainPerc], seed=randSeed)\n",
    "\n",
    "# fit a random forest\n",
    "estim = RandomForestClassifier(numTrees=20)\n",
    "fitModel = estim.fit(trn)\n",
    "trainRes = fitModel.evaluate(trn)\n",
    "trainAcc = acc.evaluate(trainRes.predictions)\n",
    "\n",
    "# now evaluate test accuracy\n",
    "testRes = fitModel.transform(tst)\n",
    "testAcc = acc.evaluate(testRes)\n",
    "\n",
    "print('Train True Positive Rate = %0.5f, Test True Positive Rate = %0.5f'%(trainAcc, testAcc))\n",
    "\n",
    "# show the results for fraudulents\n",
    "print('Training')\n",
    "trainRes.predictions.select('job_id', 'label', 'prediction').where(col('label')==1).show(10)\n",
    "print('Testing')\n",
    "testRes.select('job_id', 'label', 'prediction').where(col('label')==1).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aecdc63-3eb5-40c2-b1f9-14659b57ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view feature importances for random forest from word2vec\n",
    "imports = estim.featureImportances.toArray()\n",
    "imports = pd.DataFrame(data=imports, columns=['Importance']).sort_values(by='Importance', ascending=False, inplace=False)\n",
    "display(imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda641a-adfd-4c5c-8b5e-3435500c40cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c3c52a-a164-4c10-ba21-0193122c4e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
