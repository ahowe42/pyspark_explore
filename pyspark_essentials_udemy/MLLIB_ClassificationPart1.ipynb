{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6884cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *#avg, count, expr\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, MinMaxScaler\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import mlflow\n",
    "from mlflow import pyspark\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c365c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 cores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.150.128:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>exploreReadWrite</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd4b808b0d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize\n",
    "sc = pyspark.SparkContext()\n",
    "spark = SparkSession(sc)\n",
    "spark.sparkContext.appName = 'exploreReadWrite'\n",
    "# show the number of cores\n",
    "print('%d cores'%spark._jsc.sc().getExecutorMemoryStatus().keySet().size())\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b238b49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1054 records\n",
      "+-------+---+---+---+---+---+---+---+---+---+---+--------+--------------+---+--------------+--------+-------------------+------------------------+-----------------+\n",
      "|Case_No|A1 |A2 |A3 |A4 |A5 |A6 |A7 |A8 |A9 |A10|Age_Mons|Qchat-10-Score|Sex|Ethnicity     |Jaundice|Family_mem_with_ASD|Who completed the test  |Class/ASD Traits |\n",
      "+-------+---+---+---+---+---+---+---+---+---+---+--------+--------------+---+--------------+--------+-------------------+------------------------+-----------------+\n",
      "|1      |0  |0  |0  |0  |0  |0  |1  |1  |0  |1  |28      |3             |f  |middle eastern|yes     |no                 |family member           |No               |\n",
      "|2      |1  |1  |0  |0  |0  |1  |1  |0  |0  |0  |36      |4             |m  |White European|yes     |no                 |family member           |Yes              |\n",
      "|3      |1  |0  |0  |0  |0  |0  |1  |1  |0  |1  |36      |4             |m  |middle eastern|yes     |no                 |family member           |Yes              |\n",
      "|4      |1  |1  |1  |1  |1  |1  |1  |1  |1  |1  |24      |10            |m  |Hispanic      |no      |no                 |family member           |Yes              |\n",
      "|5      |1  |1  |0  |1  |1  |1  |1  |1  |1  |1  |20      |9             |f  |White European|no      |yes                |family member           |Yes              |\n",
      "|6      |1  |1  |0  |0  |1  |1  |1  |1  |1  |1  |21      |8             |m  |black         |no      |no                 |family member           |Yes              |\n",
      "|7      |1  |0  |0  |1  |1  |1  |0  |0  |1  |0  |33      |5             |m  |asian         |yes     |no                 |family member           |Yes              |\n",
      "|8      |0  |1  |0  |0  |1  |0  |1  |1  |1  |1  |33      |6             |m  |asian         |yes     |no                 |family member           |Yes              |\n",
      "|9      |0  |0  |0  |0  |0  |0  |1  |0  |0  |1  |36      |2             |m  |asian         |no      |no                 |family member           |No               |\n",
      "|10     |1  |1  |1  |0  |1  |1  |0  |1  |1  |1  |22      |8             |m  |south asian   |no      |no                 |Health Care Professional|Yes              |\n",
      "|11     |1  |0  |0  |1  |0  |1  |1  |0  |1  |1  |36      |6             |m  |Hispanic      |yes     |yes                |family member           |Yes              |\n",
      "|12     |1  |1  |1  |1  |0  |1  |1  |1  |0  |1  |17      |8             |m  |middle eastern|yes     |no                 |family member           |Yes              |\n",
      "|13     |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |25      |0             |f  |middle eastern|yes     |no                 |family member           |No               |\n",
      "|14     |1  |1  |1  |1  |0  |0  |1  |0  |1  |1  |15      |7             |f  |middle eastern|yes     |no                 |family member           |Yes              |\n",
      "|15     |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |18      |0             |m  |middle eastern|no      |no                 |family member           |No               |\n",
      "|16     |1  |1  |1  |0  |1  |0  |1  |1  |0  |1  |12      |7             |m  |black         |no      |no                 |family member           |Yes              |\n",
      "|17     |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |36      |0             |m  |middle eastern|no      |yes                |family member           |No               |\n",
      "|18     |1  |1  |1  |0  |1  |1  |1  |1  |0  |1  |12      |8             |f  |middle eastern|yes     |no                 |family member           |Yes              |\n",
      "|19     |1  |0  |0  |0  |1  |0  |0  |0  |0  |1  |29      |3             |f  |middle eastern|no      |no                 |family member           |No               |\n",
      "|20     |1  |1  |1  |0  |1  |0  |1  |1  |0  |1  |12      |7             |f  |black         |no      |no                 |family member           |Yes              |\n",
      "+-------+---+---+---+---+---+---+---+---+---+---+--------+--------------+---+--------------+--------+-------------------+------------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "fil = '../data/Toddler_Autism_dataset_July_2018.csv'\n",
    "schem = StructType([StructField('Case_No', IntegerType()), StructField('A1', IntegerType()), StructField('A2', IntegerType()),\n",
    "                    StructField('A3', IntegerType()), StructField('A4', IntegerType()), StructField('A5', IntegerType()),\n",
    "                    StructField('A6', IntegerType()), StructField('A7', IntegerType()), StructField('A8', IntegerType()),\n",
    "                    StructField('A9', IntegerType()), StructField('A10', IntegerType()), StructField('Age_Mons', IntegerType()),\n",
    "                    StructField('Qchat-10-Score', IntegerType()), StructField('Sex', StringType()), StructField('Ethnicity', StringType()),\n",
    "                    StructField('Jaundice', StringType()), StructField('Family_mem_with_ASD', StringType()),\n",
    "                    StructField('Who completed the test', StringType()), StructField('Class/ASD Traits ', StringType())])\n",
    "\n",
    "asd = spark.read.format('csv').options(header=True).schema(schem).load(fil)\n",
    "print('%d records'%asd.count())\n",
    "asd.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26eba72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|Class/ASD Traits |count|\n",
      "+-----------------+-----+\n",
      "|               No|  326|\n",
      "|              Yes|  728|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "responseVar = 'Class/ASD Traits '\n",
    "asd.groupBy(responseVar).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c40337b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>...</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>label_str</th>\n",
       "      <th>label</th>\n",
       "      <th>Jaundice_int</th>\n",
       "      <th>Family_mem_with_ASD_int</th>\n",
       "      <th>Who completed the test_int</th>\n",
       "      <th>Ethnicity_int</th>\n",
       "      <th>Sex_int</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>Health Care Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  ...  Family_mem_with_ASD  \\\n",
       "0        1   0   0   0   0   0   0   1   1   0  ...                   no   \n",
       "1        2   1   1   0   0   0   1   1   0   0  ...                   no   \n",
       "2        3   1   0   0   0   0   0   1   1   0  ...                   no   \n",
       "3        4   1   1   1   1   1   1   1   1   1  ...                   no   \n",
       "4        5   1   1   0   1   1   1   1   1   1  ...                  yes   \n",
       "5        6   1   1   0   0   1   1   1   1   1  ...                   no   \n",
       "6        7   1   0   0   1   1   1   0   0   1  ...                   no   \n",
       "7        8   0   1   0   0   1   0   1   1   1  ...                   no   \n",
       "8        9   0   0   0   0   0   0   1   0   0  ...                   no   \n",
       "9       10   1   1   1   0   1   1   0   1   1  ...                   no   \n",
       "\n",
       "     Who completed the test  label_str label Jaundice_int  \\\n",
       "0             family member         No   1.0          1.0   \n",
       "1             family member        Yes   0.0          1.0   \n",
       "2             family member        Yes   0.0          1.0   \n",
       "3             family member        Yes   0.0          0.0   \n",
       "4             family member        Yes   0.0          0.0   \n",
       "5             family member        Yes   0.0          0.0   \n",
       "6             family member        Yes   0.0          1.0   \n",
       "7             family member        Yes   0.0          1.0   \n",
       "8             family member         No   1.0          0.0   \n",
       "9  Health Care Professional        Yes   0.0          0.0   \n",
       "\n",
       "  Family_mem_with_ASD_int Who completed the test_int Ethnicity_int Sex_int  \\\n",
       "0                     0.0                        0.0           2.0     1.0   \n",
       "1                     0.0                        0.0           0.0     0.0   \n",
       "2                     0.0                        0.0           2.0     0.0   \n",
       "3                     0.0                        0.0           5.0     0.0   \n",
       "4                     1.0                        0.0           0.0     1.0   \n",
       "5                     0.0                        0.0           4.0     0.0   \n",
       "6                     0.0                        0.0           1.0     0.0   \n",
       "7                     0.0                        0.0           1.0     0.0   \n",
       "8                     0.0                        0.0           1.0     0.0   \n",
       "9                     0.0                        1.0           3.0     0.0   \n",
       "\n",
       "                                            features  \n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...  \n",
       "1  (1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...  \n",
       "2  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...  \n",
       "3  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "4  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "5  [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "6  (1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...  \n",
       "7  (0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...  \n",
       "8  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "9  [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(17,[6,7,9,10,11,...|  1.0|\n",
      "|(17,[0,1,5,6,10,1...|  0.0|\n",
      "|(17,[0,6,7,9,10,1...|  0.0|\n",
      "|[1.0,1.0,1.0,1.0,...|  0.0|\n",
      "|[1.0,1.0,0.0,1.0,...|  0.0|\n",
      "|[1.0,1.0,0.0,0.0,...|  0.0|\n",
      "|(17,[0,3,4,5,8,10...|  0.0|\n",
      "|(17,[1,4,6,7,8,9,...|  0.0|\n",
      "|(17,[6,9,10,11,13...|  1.0|\n",
      "|[1.0,1.0,1.0,0.0,...|  0.0|\n",
      "|[1.0,0.0,0.0,1.0,...|  0.0|\n",
      "|[1.0,1.0,1.0,1.0,...|  0.0|\n",
      "|(17,[10,12,13,14]...|  1.0|\n",
      "|[1.0,1.0,1.0,1.0,...|  0.0|\n",
      "|(17,[10,13],[18.0...|  1.0|\n",
      "|(17,[0,1,2,4,6,7,...|  0.0|\n",
      "|(17,[10,13,15],[3...|  1.0|\n",
      "|[1.0,1.0,1.0,0.0,...|  0.0|\n",
      "|(17,[0,4,9,10,11,...|  1.0|\n",
      "|[1.0,1.0,1.0,0.0,...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "First row features = (17,[6,7,9,10,11,12,13,14],[1.0,1.0,1.0,28.0,3.0,1.0,2.0,1.0])\n"
     ]
    }
   ],
   "source": [
    "''' prep the data for modeling '''\n",
    "# set inputs\n",
    "inputColumns = asd.columns[1:-1]\n",
    "strFeats = {c:c+'_int' for c in inputColumns if asd.schema[c].dataType is StringType()}\n",
    "inputColumns = [strFeats.get(c, c) for c in inputColumns]\n",
    "\n",
    "# create all numerical features & numerical response\n",
    "indxr = StringIndexer(inputCols=list(strFeats.keys()) + ['label_str'], outputCols=list(strFeats.values()) + ['label'])\n",
    "asdML = asd.withColumnRenamed(responseVar, 'label_str')\n",
    "asdML = indxr.fit(asdML).transform(asdML)\n",
    "\n",
    "# create the features vector\n",
    "assr = VectorAssembler(inputCols=inputColumns, outputCol='features')\n",
    "asdML = assr.transform(asdML)\n",
    "\n",
    "# talk\n",
    "display(asdML.limit(10).toPandas())\n",
    "asdML.select('features', 'label').show(truncate=True)\n",
    "asdML.select('features').take(1)\n",
    "print('First row features = %s'%asdML.select('features').take(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d650d61f-d8ff-43ee-bc70-f360d8d01c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cases\n",
      "+-------+\n",
      "|Case_No|\n",
      "+-------+\n",
      "|      1|\n",
      "|      2|\n",
      "|      4|\n",
      "|      5|\n",
      "|      6|\n",
      "|      8|\n",
      "|     11|\n",
      "|     12|\n",
      "|     13|\n",
      "|     17|\n",
      "|     18|\n",
      "|     19|\n",
      "|     21|\n",
      "|     23|\n",
      "|     26|\n",
      "|     27|\n",
      "|     28|\n",
      "|     32|\n",
      "|     34|\n",
      "|     37|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Testing Cases\n",
      "+-------+\n",
      "|Case_No|\n",
      "+-------+\n",
      "|      3|\n",
      "|      7|\n",
      "|      9|\n",
      "|     10|\n",
      "|     14|\n",
      "|     15|\n",
      "|     16|\n",
      "|     20|\n",
      "|     22|\n",
      "|     24|\n",
      "|     25|\n",
      "|     29|\n",
      "|     30|\n",
      "|     31|\n",
      "|     33|\n",
      "|     35|\n",
      "|     36|\n",
      "|     40|\n",
      "|     43|\n",
      "|     44|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' split for cross-val '''\n",
    "trainPerc = 0.7\n",
    "randSeed = 42\n",
    "trainASD, testASD = asdML.randomSplit([trainPerc, 1.0 - trainPerc], seed=randSeed)\n",
    "\n",
    "# talk\n",
    "print('Training Cases')\n",
    "trainASD.select('Case_No').show()\n",
    "print('Testing Cases')\n",
    "testASD.select('Case_No').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0655d-3ede-4ef2-9c56-965e99f46864",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff62c1a3-2b74-4be2-bb2e-5e006282894e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy = 1.000, Test Accurcy = 1.000\n"
     ]
    }
   ],
   "source": [
    "''' try logistic regression - using predefined train/test split '''\n",
    "# create objects\n",
    "#auc = BinaryClassificationEvaluator(metricName='areaUnderROC')\n",
    "acc = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# train & eval\n",
    "fitModel = logreg.fit(trainASD.select('features', 'label'))\n",
    "trainRes = fitModel.evaluate(trainASD.select('features', 'label'))\n",
    "trainAcc = acc.evaluate(trainRes.predictions)\n",
    "\n",
    "# now evaluate test accuracy\n",
    "testRes = fitModel.transform(testASD.select('features', 'label'))\n",
    "testAcc = acc.evaluate(testRes)\n",
    "\n",
    "print('Train Accuracy = %0.3f, Test Accurcy = %0.3f'%(trainAcc, testAcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc56dd55-460d-4952-aaf9-0c390b261aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' now use the builtin cross-validator '''\n",
    "#estimator\n",
    "logreg = LogisticRegression()\n",
    "# parameters grid\n",
    "params = (ParamGridBuilder().addGrid(logreg.threshold, [0.4, 0.5, 0.6]).addGrid(logreg.elasticNetParam, [0.0, 0.25, 0.5, 0.75, 1.0]).build())\n",
    "# cross-validator\n",
    "cv = CrossValidator(estimator=logreg, estimatorParamMaps=params, evaluator=acc, numFolds=5)\n",
    "\n",
    "# run\n",
    "fitModel = cv.fit(trainASD.select('features', 'label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d70fa3ef-fd2b-4284-92e5-d2e77681d202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold = 0.400, Elastic Net = 0.000\n",
      "Best Model Test Accuracy = 1.000\n"
     ]
    }
   ],
   "source": [
    "bestModel = fitModel.bestModel\n",
    "\n",
    "# best model parameters\n",
    "print('Threshold = %0.3f, Elastic Net = %0.3f'%(bestModel.getThreshold(), bestModel.getElasticNetParam()))\n",
    "\n",
    "# show performance of best model\n",
    "testAcc = acc.evaluate(bestModel.transform(testASD.select('features', 'label')))\n",
    "print('Best Model Test Accuracy = %0.3f'%testAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71310ec7-823d-4291-a316-fa54ce89150e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+\n",
      "|summary|              label|         prediction|\n",
      "+-------+-------------------+-------------------+\n",
      "|  count|                780|                780|\n",
      "|   mean|0.30256410256410254|0.30256410256410254|\n",
      "| stddev| 0.4596628666274773| 0.4596628666274773|\n",
      "|    min|                0.0|                0.0|\n",
      "|    max|                1.0|                1.0|\n",
      "+-------+-------------------+-------------------+\n",
      "\n",
      "Summary Information ['accuracy', 'areaUnderROC', 'fMeasureByLabel', 'fMeasureByThreshold', 'falsePositiveRateByLabel', 'featuresCol', 'labelCol', 'labels', 'objectiveHistory', 'pr', 'precisionByLabel', 'precisionByThreshold', 'predictionCol', 'predictions', 'probabilityCol', 'recallByLabel', 'recallByThreshold', 'roc', 'scoreCol', 'totalIterations', 'truePositiveRateByLabel', 'weightCol', 'weightedFMeasure', 'weightedFalsePositiveRate', 'weightedPrecision', 'weightedRecall', 'weightedTruePositiveRate']\n"
     ]
    }
   ],
   "source": [
    "# only available for logistic regression\n",
    "summ = bestModel.summary\n",
    "summ.predictions.describe().show()\n",
    "summ.objectiveHistory\n",
    "\n",
    "print('Summary Information %s'%[am for am in dir(summ) if am[0] != '_'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30168f5-3727-4833-8da3-526666c98f72",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39c192de-f448-4364-bafb-380b1a55030f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' now use the builtin cross-validator '''\n",
    "#estimator\n",
    "estim = DecisionTreeClassifier()\n",
    "# parameters grid\n",
    "params = (ParamGridBuilder().addGrid(estim.maxBins, [20, 40, 80, 100])\\\n",
    "              .addGrid(estim.maxDepth, [5, 10, 30]).build())\n",
    "# cross-validator\n",
    "cv = CrossValidator(estimator=estim, estimatorParamMaps=params, evaluator=acc, numFolds=5)\n",
    "\n",
    "# run\n",
    "fitModel = cv.fit(trainASD.select('features', 'label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67ae3692-6596-4676-9d04-d1d7722d8b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Quant Bins = 20.000, Max Depth = 5.000\n",
      "Best Model Test Accuracy = 1.000\n",
      "A1 feature importance = 0.000\n",
      "A2 feature importance = 0.000\n",
      "A3 feature importance = 0.000\n",
      "A4 feature importance = 0.000\n",
      "A5 feature importance = 0.000\n",
      "A6 feature importance = 0.000\n",
      "A7 feature importance = 0.000\n",
      "A8 feature importance = 0.000\n",
      "A9 feature importance = 0.000\n",
      "A10 feature importance = 0.000\n",
      "Age_Mons feature importance = 0.000\n",
      "Qchat-10-Score feature importance = 1.000\n",
      "Sex_int feature importance = 0.000\n",
      "Ethnicity_int feature importance = 0.000\n",
      "Jaundice_int feature importance = 0.000\n",
      "Family_mem_with_ASD_int feature importance = 0.000\n",
      "Who completed the test_int feature importance = 0.000\n"
     ]
    }
   ],
   "source": [
    "bestModel = fitModel.bestModel\n",
    "\n",
    "# best model parameters\n",
    "print('Max Quant Bins = %0.3f, Max Depth = %0.3f'%(bestModel.getMaxBins(), bestModel.getMaxDepth()))\n",
    "\n",
    "# show performance of best model\n",
    "testAcc = acc.evaluate(bestModel.transform(testASD.select('features', 'label')))\n",
    "print('Best Model Test Accuracy = %0.3f'%testAcc)\n",
    "\n",
    "# view feature importances\n",
    "imports = bestModel.featureImportances.toArray()\n",
    "for (col, imp) in zip(inputColumns, imports):\n",
    "    print('%s feature importance = %0.3f'%(col, imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c08a383-61ab-478b-86e8-755c6c206a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cacheNodeIds',\n",
       " 'checkpointInterval',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'depth',\n",
       " 'explainParam',\n",
       " 'explainParams',\n",
       " 'extractParamMap',\n",
       " 'featureImportances',\n",
       " 'featuresCol',\n",
       " 'getCacheNodeIds',\n",
       " 'getCheckpointInterval',\n",
       " 'getFeaturesCol',\n",
       " 'getImpurity',\n",
       " 'getLabelCol',\n",
       " 'getLeafCol',\n",
       " 'getMaxBins',\n",
       " 'getMaxDepth',\n",
       " 'getMaxMemoryInMB',\n",
       " 'getMinInfoGain',\n",
       " 'getMinInstancesPerNode',\n",
       " 'getMinWeightFractionPerNode',\n",
       " 'getOrDefault',\n",
       " 'getParam',\n",
       " 'getPredictionCol',\n",
       " 'getProbabilityCol',\n",
       " 'getRawPredictionCol',\n",
       " 'getSeed',\n",
       " 'getThresholds',\n",
       " 'getWeightCol',\n",
       " 'hasDefault',\n",
       " 'hasParam',\n",
       " 'impurity',\n",
       " 'isDefined',\n",
       " 'isSet',\n",
       " 'labelCol',\n",
       " 'leafCol',\n",
       " 'load',\n",
       " 'maxBins',\n",
       " 'maxDepth',\n",
       " 'maxMemoryInMB',\n",
       " 'minInfoGain',\n",
       " 'minInstancesPerNode',\n",
       " 'minWeightFractionPerNode',\n",
       " 'numClasses',\n",
       " 'numFeatures',\n",
       " 'numNodes',\n",
       " 'params',\n",
       " 'predict',\n",
       " 'predictLeaf',\n",
       " 'predictProbability',\n",
       " 'predictRaw',\n",
       " 'predictionCol',\n",
       " 'probabilityCol',\n",
       " 'rawPredictionCol',\n",
       " 'read',\n",
       " 'save',\n",
       " 'seed',\n",
       " 'set',\n",
       " 'setFeaturesCol',\n",
       " 'setLeafCol',\n",
       " 'setPredictionCol',\n",
       " 'setProbabilityCol',\n",
       " 'setRawPredictionCol',\n",
       " 'setThresholds',\n",
       " 'supportedImpurities',\n",
       " 'thresholds',\n",
       " 'toDebugString',\n",
       " 'transform',\n",
       " 'uid',\n",
       " 'weightCol',\n",
       " 'write']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is available in the model object\n",
    "print([i for i in dir(bestModel) if i[0] != '_'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ebb6a6-cbe2-4b9a-a0cc-2b2e18154185",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51e18a85-2b41-4eef-a157-d0fd467838d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' now use the builtin cross-validator '''\n",
    "#estimator\n",
    "estim = RandomForestClassifier(numTrees=20)\n",
    "# parameters grid\n",
    "params = (ParamGridBuilder().addGrid(estim.maxBins, [20, 40, 80, 100])\\\n",
    "              .addGrid(estim.maxDepth, [5, 10, 30]).build())\n",
    "# cross-validator\n",
    "cv = CrossValidator(estimator=estim, estimatorParamMaps=params, evaluator=acc, numFolds=5)\n",
    "\n",
    "# run\n",
    "fitModel = cv.fit(trainASD.select('features', 'label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d28f183-54a6-4d4e-80a5-63fecfe6107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Quant Bins = 20.000, Max Depth = 5.000\n",
      "Best Model Test Accuracy = 1.000\n",
      "A1 feature importance = 0.030\n",
      "A2 feature importance = 0.029\n",
      "A3 feature importance = 0.007\n",
      "A4 feature importance = 0.041\n",
      "A5 feature importance = 0.040\n",
      "A6 feature importance = 0.041\n",
      "A7 feature importance = 0.080\n",
      "A8 feature importance = 0.006\n",
      "A9 feature importance = 0.071\n",
      "A10 feature importance = 0.003\n",
      "Age_Mons feature importance = 0.002\n",
      "Qchat-10-Score feature importance = 0.646\n",
      "Sex_int feature importance = 0.000\n",
      "Ethnicity_int feature importance = 0.003\n",
      "Jaundice_int feature importance = 0.000\n",
      "Family_mem_with_ASD_int feature importance = 0.000\n",
      "Who completed the test_int feature importance = 0.001\n"
     ]
    }
   ],
   "source": [
    "bestModel = fitModel.bestModel\n",
    "\n",
    "# best model parameters\n",
    "print('Max Quant Bins = %0.3f, Max Depth = %0.3f'%(bestModel.getMaxBins(), bestModel.getMaxDepth()))\n",
    "\n",
    "# show performance of best model\n",
    "testAcc = acc.evaluate(bestModel.transform(testASD.select('features', 'label')))\n",
    "print('Best Model Test Accuracy = %0.3f'%testAcc)\n",
    "\n",
    "# view feature importances\n",
    "imports = bestModel.featureImportances.toArray()\n",
    "for (col, imp) in zip(inputColumns, imports):\n",
    "    print('%s feature importance = %0.3f'%(col, imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "659167de-a59b-4761-aae9-6719d3268fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bootstrap', 'cacheNodeIds', 'checkpointInterval', 'clear', 'copy', 'evaluate', 'explainParam', 'explainParams', 'extractParamMap', 'featureImportances', 'featureSubsetStrategy', 'featuresCol', 'getBootstrap', 'getCacheNodeIds', 'getCheckpointInterval', 'getFeatureSubsetStrategy', 'getFeaturesCol', 'getImpurity', 'getLabelCol', 'getLeafCol', 'getMaxBins', 'getMaxDepth', 'getMaxMemoryInMB', 'getMinInfoGain', 'getMinInstancesPerNode', 'getMinWeightFractionPerNode', 'getNumTrees', 'getOrDefault', 'getParam', 'getPredictionCol', 'getProbabilityCol', 'getRawPredictionCol', 'getSeed', 'getSubsamplingRate', 'getThresholds', 'getWeightCol', 'hasDefault', 'hasParam', 'hasSummary', 'impurity', 'isDefined', 'isSet', 'labelCol', 'leafCol', 'load', 'maxBins', 'maxDepth', 'maxMemoryInMB', 'minInfoGain', 'minInstancesPerNode', 'minWeightFractionPerNode', 'numClasses', 'numFeatures', 'numTrees', 'params', 'predict', 'predictLeaf', 'predictProbability', 'predictRaw', 'predictionCol', 'probabilityCol', 'rawPredictionCol', 'read', 'save', 'seed', 'set', 'setFeaturesCol', 'setLeafCol', 'setPredictionCol', 'setProbabilityCol', 'setRawPredictionCol', 'setThresholds', 'subsamplingRate', 'summary', 'supportedFeatureSubsetStrategies', 'supportedImpurities', 'thresholds', 'toDebugString', 'totalNumNodes', 'transform', 'treeWeights', 'trees', 'uid', 'weightCol', 'write']\n"
     ]
    }
   ],
   "source": [
    "# what is available in the model object\n",
    "print([i for i in dir(bestModel) if i[0] != '_'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1926fff6-d845-4919-9993-f1dc0b6ab6aa",
   "metadata": {},
   "source": [
    "### Now try mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e068e40e-63c1-4991-8eea-3088fc652cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'My Experiment'\n",
    "mlflow.set_experiment(experiment_name='My Experiment')\n",
    "mlfc = MlflowClient()\n",
    "\n",
    "experiments = mlfc.list_experiments()\n",
    "\n",
    "def create_run(expName, mlFlowClient):\n",
    "    mlflow.set_experiment(experiment_name='My Experiment')\n",
    "    experiments = mlFlowClient.list_experiments()\n",
    "    for exp in experiments:\n",
    "        if expName in exp.name:\n",
    "            expIndex = experiments.index(exp)\n",
    "            run = mlFlowClient.create_run(experiments[expIndex].experiment_id)\n",
    "            print(run)\n",
    "            return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eaea8644-7ffc-4abb-99c5-fb35404fedcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Run: data=<RunData: metrics={}, params={}, tags={}>, info=<RunInfo: artifact_uri='file:///home/ahowe42/pyspark_explore/pyspark_essentials_udemy/mlruns/1/fd5f0a7fdafe4928994faead5b122bef/artifacts', end_time=None, experiment_id='1', lifecycle_stage='active', run_id='fd5f0a7fdafe4928994faead5b122bef', run_uuid='fd5f0a7fdafe4928994faead5b122bef', start_time=1622235063594, status='RUNNING', user_id='unknown'>>\n",
      "Threshold = 0.500, Elastic Net = 0.000\n",
      "Best Model Test Accuracy = 1.000\n"
     ]
    }
   ],
   "source": [
    "''' use mlflow with the cross validator now '''\n",
    "run = create_run(experiment_name, mlfc)\n",
    "\n",
    "#estimator\n",
    "estim = LogisticRegression()\n",
    "estimName = 'LogisticReg'\n",
    "# parameters grid\n",
    "params = (ParamGridBuilder().addGrid(estim.threshold, [0.4, 0.5, 0.6]).addGrid(estim.elasticNetParam, [0.0, 0.25, 0.5, 0.75, 1.0]).build())\n",
    "paramNames = ['threshold', 'elasticnetparam']\n",
    "# cross-validator\n",
    "cv = CrossValidator(estimator=logreg, estimatorParamMaps=params, evaluator=acc, numFolds=5)\n",
    "# run\n",
    "fitModel = cv.fit(trainASD.select('features', 'label'))\n",
    "\n",
    "# get results\n",
    "bestModel = fitModel.bestModel\n",
    "# best model parameters\n",
    "print('Threshold = %0.3f, Elastic Net = %0.3f'%(bestModel.getThreshold(), bestModel.getElasticNetParam()))\n",
    "# show performance of best model\n",
    "testAcc = acc.evaluate(bestModel.transform(testASD.select('features', 'label')))\n",
    "print('Best Model Test Accuracy = %0.3f'%testAcc)\n",
    "# get best parameters\n",
    "bestParams = bestModel.extractParamMap()\n",
    "\n",
    "# add stuff to mlflow\n",
    "mlfc.set_tag(run.info.run_id, 'Estimator', estimName)\n",
    "mlfc.set_tag(run.info.run_id, 'PRNG Seed', randSeed)\n",
    "mlfc.set_tag(run.info.run_id, 'Train Perc', trainPerc)\n",
    "for (key, val) in bestParams.items():\n",
    "    for parm in paramNames:\n",
    "        if parm in key.name.lower():\n",
    "            mlfc.log_param(run.info.run_id, parm, val)\n",
    "mlfc.log_metric(run.info.run_id, 'Accuracy', testAcc)\n",
    "mlfc.set_terminated(run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf575fc-a325-42d5-aa00-42bed99e0cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f96928b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c22f013-c95e-48c7-8bda-edff5bb310e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
