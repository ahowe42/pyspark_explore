{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6884cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler, OneHotEncoder, MinMaxScaler, StringIndexer\n",
    "from pyspark.ml.clustering import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c365c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "sc = pyspark.SparkContext()\n",
    "spark = SparkSession(sc)\n",
    "spark.sparkContext.appName = 'cluster'\n",
    "# show the number of cores\n",
    "print('%d cores'%spark._jsc.sc().getExecutorMemoryStatus().keySet().size())\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b238b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' get the data '''\n",
    "# load the data\n",
    "fil = '../data/credict_card_data.csv'\n",
    "schem = StructType([StructField('CUST_ID', StringType()), StructField('BALANCE', FloatType()),\n",
    "                    StructField('BALANCE_FREQUENCY', FloatType()), StructField('PURCHASES', FloatType()),\n",
    "                    StructField('ONEOFF_PURCHASES', FloatType()), StructField('INSTALLMENTS_PURCHASES', FloatType()),\n",
    "                    StructField('CASH_ADVANCE', FloatType()), StructField('PURCHASES_FREQUENCY', FloatType()),\n",
    "                    StructField('ONEOFF_PURCHASES_FREQUENCY', FloatType()),\n",
    "                    StructField('PURCHASES_INSTALLMENTS_FREQUENCY', FloatType()),\n",
    "                    StructField('CASH_ADVANCE_FREQUENCY', FloatType()), StructField('CASH_ADVANCE_TRX', FloatType()),\n",
    "                    StructField('PURCHASES_TRX', FloatType()), StructField('CREDIT_LIMIT', FloatType()),\n",
    "                    StructField('PAYMENTS', FloatType()), StructField('MINIMUM_PAYMENTS', FloatType()),\n",
    "                    StructField('PRC_FULL_PAYMENT', FloatType()), StructField('TENURE', IntegerType())])\n",
    "cc = spark.read.format('csv').options(header=True).schema(schem).load(fil)\n",
    "\n",
    "# talk\n",
    "cnt = cc.count()\n",
    "print('%d records'%cc)\n",
    "house.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e099cfe-d4ff-487c-8969-626e2f2f9f9c",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b443b6-ca5e-4629-9aec-a3ce22320110",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' handle missing values '''\n",
    "# check for missing values\n",
    "nullCounts = {colm:house.select(colm).where(col(colm).isNull()).count() for colm in house.columns}\n",
    "nullCounts = {colm:(ncnt, ncnt/cnt) for (colm, ncnt) in nullCounts.items()}\n",
    "nullCountsDF = pd.DataFrame(nullCounts).T.reset_index(drop=False).sort_values(1, ascending=False)\n",
    "nullCountsDF.columns = ['Column', 'Freq.', 'Rel. Freq.']\n",
    "nullCountsDF = nullCountsDF.merge(pd.DataFrame([[colm.name, colm.dataType] for colm in house.schema], columns=['Column', 'Type']),\n",
    "                                how='inner', on=['Column'])\n",
    "\n",
    "# talk\n",
    "display(nullCountsDF)\n",
    "\n",
    "# remove\n",
    "house = house.dropna(how='any')\n",
    "\n",
    "# talk some more\n",
    "print('%d records'%house.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfb0121-3f5d-4035-85bd-585dd6f97325",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' OHE the ocean_proximity var '''\n",
    "# first review the distribution\n",
    "tab = house.groupBy('ocean_proximity').count().toPandas().sort_values(by='ocean_proximity')\n",
    "display(tab)\n",
    "\n",
    "# first need to string index ...\n",
    "indx = StringIndexer(inputCol='ocean_proximity', outputCol='oceanProx_int', stringOrderType='alphabetAsc')\n",
    "house = indx.fit(house).transform(house)\n",
    "\n",
    "# ... then we can encode\n",
    "ohe = OneHotEncoder(inputCol='oceanProx_int', outputCol='oceanProx')\n",
    "house = ohe.fit(house).transform(house).drop('oceanProx_int')\n",
    "\n",
    "# make the OHE columns - last is excluded; when all are 0, it's the last\n",
    "featOHE = ['oceanProx_%s'%c for c in tab.ocean_proximity.values[:-1]]\n",
    "print(featOHE)\n",
    "\n",
    "# talk\n",
    "house.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eba72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the response\n",
    "house = house.withColumnRenamed('median_house_value', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c40337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' prepare the features '''\n",
    "# get the features\n",
    "features = [c for c in house.columns if c not in (['ocean_proximity', 'label', 'id'])]\n",
    "\n",
    "# create & scale the features vector\n",
    "assr = VectorAssembler(inputCols=features, outputCol='features_raw')\n",
    "scalr = MinMaxScaler(inputCol='features_raw', outputCol='features')\n",
    "pipe = Pipeline(stages=[assr, scalr]).fit(house)\n",
    "house = pipe.transform(house).drop('features_raw')\n",
    "\n",
    "# now update the features list with the ocean proximity OHE columns; this assumes\n",
    "# oceanProx was the last column, which should be true\n",
    "features = features[:-1] + featOHE\n",
    "print(features)\n",
    "\n",
    "# talk\n",
    "display(house.limit(10).toPandas())\n",
    "house.select('id', 'features', 'label').show(truncate=False)\n",
    "house.select('features').take(1)\n",
    "print('First row features = %s'%house.select('features').take(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e84eb-4165-48f9-be0c-0b23c1c54153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for multicollinearity\n",
    "# high: total_bedrooms vs. households, population vs. households, \n",
    "corr = Correlation.corr(house, column='features', method='pearson')\n",
    "corrdf = pd.DataFrame(index=features, data=corr.collect()[0][0].toArray(), columns=features)\n",
    "display(corrdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bf49cf-1a63-4978-87fc-1b07b093f160",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d650d61f-d8ff-43ee-bc70-f360d8d01c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split for cross-val\n",
    "trainPerc = 0.7\n",
    "randSeed = 42\n",
    "tran, test = house.select('id', 'label', 'features').randomSplit([trainPerc, 1.0 - trainPerc], seed=randSeed)\n",
    "\n",
    "# talk\n",
    "print('Training Cases')\n",
    "tran.select('id').show()\n",
    "print('Testing Cases')\n",
    "test.select('id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94df9aae-79fb-48b9-acd2-4b13ca9e033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' set up the estimators & param grids '''\n",
    "models = {}\n",
    "\n",
    "'''# linear regression\n",
    "linreg = LinearRegression()\n",
    "params = (ParamGridBuilder().addGrid(linreg.elasticNetParam, [0.0, 0.25, 0.5, 0.75, 1.0]).build())\n",
    "paramNames = ['elasticnetparam']\n",
    "models['linear regression'] = [linreg, params, paramNames, None, None]\n",
    "\n",
    "# random forest\n",
    "ranfor = RandomForestRegressor(numTrees=20)\n",
    "params = (ParamGridBuilder().addGrid(ranfor.maxBins, [20, 40, 80, 100])\\\n",
    "              .addGrid(ranfor.maxDepth, [5, 10, 30]).build())\n",
    "paramNames = ['maxbins', 'maxdepth']\n",
    "models['random forest'] = [ranfor, params, paramNames, None, None]'''\n",
    "\n",
    "# gradient boosting trees\n",
    "gradbst = GBTRegressor(maxIter=20)\n",
    "params = (ParamGridBuilder().addGrid(gradbst.maxBins, [20, 40, 80, 100])\\\n",
    "              .addGrid(gradbst.maxDepth, [5, 10, 30]).build())\n",
    "paramNames = ['maxbins', 'maxdepth']\n",
    "models['gradient boost'] = [gradbst, params, paramNames, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94258b5-fa33-490f-8fa7-23c7eef84078",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' run the models '''\n",
    "# number of cv folds\n",
    "folds = 5\n",
    "# define the evaulation function\n",
    "evl = RegressionEvaluator(metricName='rmse')\n",
    "\n",
    "# iterate over models\n",
    "for (model, stuff) in models.items():\n",
    "    print('Cross Validator: %s'%model)\n",
    "    # execute\n",
    "    cv = CrossValidator(estimator=stuff[0], estimatorParamMaps=stuff[1], evaluator=evl, numFolds=folds)\n",
    "    fitModel = cv.fit(house.select('features', 'label'))\n",
    "    # get the best\n",
    "    bestModel = fitModel.bestModel\n",
    "    # evaluate performance on the test set\n",
    "    testRMSE = evl.evaluate(bestModel.transform(test.select('features', 'label')))\n",
    "    print('\\tBest Model Test RMSE = %0.3f'%testRMSE)    \n",
    "    # get best parameters\n",
    "    bestParams = bestModel.extractParamMap()\n",
    "    for (key, val) in bestParams.items():\n",
    "        for parm in stuff[2]:\n",
    "            if parm in key.name.lower():\n",
    "                print('\\t%s = %0.2f'%(key, val))\n",
    "                break\n",
    "    # save stuff\n",
    "    models[model][3] = fitModel\n",
    "    models[model][4] = testRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b70786-9369-4d23-aa98-16585e952025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at linear regression coefficients\n",
    "bm = models['linear regression'][3].bestModel\n",
    "summ = bm.summary\n",
    "summ.predictions.describe().withColumn('Diff', col('prediction') - col('label')).show(truncate=False)\n",
    "print('Best Model RMSE = %0.3f'%summ.rootMeanSquaredError)\n",
    "\n",
    "# get a nice model coefficients table\n",
    "coefs = pd.concat([pd.DataFrame(index=['Intercept'], data=[bm.intercept], columns=['Coefficient']),\n",
    "                   pd.DataFrame(index=features, data=bm.coefficients.toArray(), columns=['Coefficient'])])\n",
    "coefs['Std. Error'] = bm.summary.coefficientStandardErrors\n",
    "coefs['pValue'] = bm.summary.pValues\n",
    "# make an absolute coef column temporarily for sorting\n",
    "coefs['tmp'] = coefs['Coefficient'].abs() a\n",
    "coefs.loc['Intercept', 'tmp'] = np.inf\n",
    "coefs = coefs.sort_values(by='tmp', ascending=False).drop(columns='tmp')\n",
    "\n",
    "# talk\n",
    "display(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf575fc-a325-42d5-aa00-42bed99e0cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view feature importances for random forest\n",
    "imports = models['random forest'][3].bestModel.featureImportances.toArray()\n",
    "imports = pd.DataFrame(index=features, data=imports, columns=['Importance']).sort_values(by='Importance', ascending=False, inplace=False)\n",
    "display(imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71d80b2-734b-4701-911a-8b9a704255de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view feature importances for gradient boost\n",
    "imports = models['gradient boost'][3].bestModel.featureImportances.toArray()\n",
    "imports = pd.DataFrame(index=features, data=imports, columns=['Importance']).sort_values(by='Importance', ascending=False, inplace=False)\n",
    "display(imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb222983-b161-44d0-ab9a-fe5689a7a1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb97571-ffcf-4106-bf93-9bae9dd9d6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96928b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c22f013-c95e-48c7-8bda-edff5bb310e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
